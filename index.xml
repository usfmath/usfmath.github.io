<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grad Math@USF</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Grad Math@USF</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 01 May 2021 15:19:15 -0400</lastBuildDate>
    <image>
      <url>/images/icon_hu52d4978bb57ec1511a90a19194ce34ae_631017_512x512_fill_lanczos_center_2.png</url>
      <title>Grad Math@USF</title>
      <link>/</link>
    </image>
    
    <item>
      <title>The Helton Howe Trace Formula</title>
      <link>/posts/the-helton-howe-trace-formula/</link>
      <pubDate>Sat, 01 May 2021 15:19:15 -0400</pubDate>
      <guid>/posts/the-helton-howe-trace-formula/</guid>
      <description>&lt;p&gt;We present a proof of a simple version of the Helton-Howe trace
formula (for a more general version of this result, one should consult
the 
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/BFb0058919&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;original paper&lt;/a&gt;).
Consider the Hardy space $H^2(\mathbb{D})$. There is a natural
inclusion of $H^2(\mathbb{D})$ into $L^2(\mathbb{T})$, given by the restriction
$f\mapsto f\vert_{\mathbb{T}}$. Let $\mathbb{P}_{H^2} : L^2(\mathbb{T}) \to H^2(\mathbb{D})$ denote the
orthogonal projection of $L^2(\mathbb{T})$ into $H^2(\mathbb{D})$. Now, given
$P \in \mathbb{C}[z,z^{-1}]$, we define the Toeplitz operator with principal
symbol $P$ by $$T_P f(z) = \mathbb{P}_{H^2} \left[ P(z)f(z)\right],$$ for
$f \in H^2(\mathbb{D})$. It is clear that the commutator of any two such
operators operators is trace-class (it is even of finite rank). The
Helton-Howe formula tells us that, given $P,Q \in \mathbb{C}[z,z^{-1}]$,
$$\text{tr } [T_P, T_Q] = \frac{1}{2\pi i}\int_{|z| = 1} P(z) Q&#39;(z) dz = \frac{1}{2\pi i}\int_{\mathbb{D}} dP \wedge dQ$$
The last equality is immediate from Stokes&#39; theorem; the interesting
equality is the first. Let $T_z$ denote the Toeplitz operator of
multiplication by $z$ (this is just the shift operator in the Hardy
space), and $T^*_z$ its adjoint (note that $T^*_z = T_{1/z}$). If
$P = \sum_k P_k z^k \in \mathbb{C}[z,z^{-1}]$, then its corresponding Toeplitz
operator may be written as
$$T_P = \sum_{k\geq 0} P_k T_z^k + \sum_{k&amp;lt;0} P_k {T_z^{*}}^k.$$
Clearly, ${T_z^*}^n{T_z}^n = I$; on the other hand,
${T_z}^n{T_z^*}^n = I - \mathbb{P}_n$, where $\mathbb{P}_n$ is the orthogonal
projector onto the subspace $E_n:=\text{span}$ {$1,z, &amp;hellip;,z^{n-1}$}.
This observation allows us to compute that
$\text{tr }[{T_z^*}^n,{T_z}^n] = \text{tr } \mathbb{P}_n = n$. Now, if $n \neq m$, one finds
by direct computation that $\text{tr }[{T_z^*}^m,{T_z}^n] = 0$. Thus,
$\text{tr }[{T_z^*}^m,{T_z}^n] = n\delta_{n,m}$. If $P, Q \in \mathbb{C}[z,z^{-1}]$,
and $P = \sum_k P_k z^k$, $Q = \sum_k Q_k z^k$, then
$$= \sum_{n,m \geq 0} (P_{-n}Q_m - Q_{-n}P_m) [{T_z^*}^n,{T_z}^m];$$
taking traces yields $$\begin{aligned}
\text{tr } [T_P,T_Q] &amp;amp;= \sum_{n,m \geq 0} (P_{-n}Q_m - Q_{-n}P_m) \text{tr } [{T_z^*}^n,{T_z}^m] \\\&lt;br&gt;
&amp;amp;= \sum_{n,m \geq 0} (P_{-n}Q_m - Q_{-n}P_m) n\delta_{n,m} = \sum_{n\geq 0} n(P_{-n}Q_n - Q_{-n}P_n)\\\&lt;br&gt;
&amp;amp;= \sum_{n}n P_{-n}Q_n.
\end{aligned}$$ On the other hand, by residue theorem,
$$\begin{aligned}
\frac{1}{2\pi i}\int_{|z| = 1} P(z) Q&#39;(z) dz
&amp;amp;= \frac{1}{2\pi i}\int_{|z| = 1} \sum_{\ell}\left(\sum_n nP_{\ell - n} Q_n \right) z^{\ell-1} dz\\\&lt;br&gt;
&amp;amp;= \sum_{\ell}\left(\sum_n nP_{\ell - n} Q_n \right) \delta_{\ell,0}\\\&lt;br&gt;
&amp;amp;= \sum_{n}n P_{-n}Q_n.
\end{aligned}$$ Comparing the results of these two computations
concludes the proof.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working Differential Geometry</title>
      <link>/posts/working-differential-geometry/</link>
      <pubDate>Sat, 01 May 2021 12:52:29 -0400</pubDate>
      <guid>/posts/working-differential-geometry/</guid>
      <description>&lt;p&gt;We present a methodical procedure for computing important geometric quantities on a Riemannian manifold. We want to emphasize that the purpose of this document is not meant to provide a systematic introduction to Riemannian geometry, or motivate/give intuition for the definitions (although we will occasionally give quick consistency checks); rather, our aim is to provide a formalism that makes the objects of interest (Christoffel symbols, Riemann tensor, etc.) &amp;ldquo;manageable&amp;rdquo;. This method is not the most streamlined (see, for example, E. Cartan&amp;rsquo;s theory of moving frames, which is arguably easier to work with; furthermore, if the manifold in question is a Lie group equipped with an invariant metric, the required computations reduce drastically), it is certainly friendlier than what is found in most classical differential geometry texts. Furthermore, most of these techniques carry over to vector and principal bundles, equipped with a connection, and so what follows may also be readily applied there. Before beginning the exposition, we summarize the objectives of this document:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. Compute several examples of Riemannian metrics.
2. Compute the Levi-Cevita connection in terms of the metric.
3. Compute the Riemann tensor in terms of the connection coefficients.
4. Compute the Ricci and scalar curvatures in terms of the Riemann tensor, 
as well as the Einstein tensor (in some special cases).
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;1-riemannian-metrics&#34;&gt;$1$. Riemannian metrics.&lt;/h2&gt;
&lt;p&gt;We will always start by fixing a local coordinate patch $(U,x)$, and work within this coordinate patch. For simplicity in our examples, we will choose manifolds/metrics which admit global coordinates. These examples will be carried throughout the text and built upon, in order to show the utility of the methods we present.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Sphere $S^2$.&lt;/em&gt;
Most commonly (and often most intuitively), a manifold is endowed with the metric arising from the restriction Euclidean metric in its embedding space to the manifold. In plain English, this means that distances are measured as they are in the embedding space, but with the additional restriction that we are required to only measure distances restricted to the surface of the space of interest. As a first example, we consider the sphere $S^2 \subset \mathbb{R}^3$. The sphere admits coordinates
$$
x = \sin \theta \cos \varphi, \qquad
y = \sin \theta \sin \varphi, \qquad
z = \cos \theta, \&lt;br&gt;
$$
where $0 \leq \theta \leq \pi, 0 \leq \varphi \leq 2 \pi$. &lt;em&gt;(Note: We are using the standard physics notation for spherical coordinates; we apologize to anyone used to the other notation, and hope it won&amp;rsquo;t cause too much confusion.&lt;/em&gt; In these coordinates, the differentials $dx$, $dy$, and $dz$ may be computed readily:
$$dx = \cos\theta \cos\varphi d\theta - \sin\theta \sin\varphi d\varphi,$$
$$dy = \cos\theta \sin\varphi d\theta + \sin\theta \cos\varphi d\varphi,$$
$$dz = -\sin\theta d\theta.$$
Taking tensor products of each coordinate is a little more tedious, but is still a feasible task (we will write expressions like $dx^2$ or $dxdy$ instead of $dx\otimes dx$ or $dx\otimes dy$, to simplify notations):
$$dx^2 = \cos^2\theta\cos^2\varphi d\theta^2 + \sin^2\theta\sin^2\varphi d\varphi^2
- \cos\theta \sin\theta \cos \varphi \sin\varphi d\theta d\varphi$$
$$ - \cos\theta \sin\theta \cos \varphi \sin\varphi  d\varphi d\theta,$$
$$dy^2 = \cos^2\theta\sin^2\varphi d\theta^2 + \sin^2\theta\cos^2\varphi d\varphi^2$$
$$+ \cos\theta \sin\theta \cos \varphi \sin\varphi d\theta d\varphi + \cos\theta \sin\theta \cos \varphi \sin\varphi  d\varphi d\theta,$$
$$dz^2 = \sin^2\theta d\theta^2.$$
Summing these three terms, we obtain the restriction of the Euclidean metric $g = dx^2 + dy^2 + dz^2$ in $\mathbb{R}^3$ to the sphere. We see that the &amp;ldquo;cross terms&amp;rdquo; (the expressions containing $d\theta d\varphi$ and $d\varphi d\theta$) cancel, and repeated use of trigonometric identities on the remaining terms yields the expression
$$ g\vert_{S^2} = d\theta^2 + \sin^2\theta d\varphi^2. $$
Instead of numbering the coordinates (which will make the notation cumbersome), we will simply use the coordinates themselves as indices, and subsequent sums over indices will be taken over these symbols. This is less complicated than it sounds: For example, the metric above has components: $g_{\theta\theta} = 1$, $g_{\theta\varphi} = g_{\varphi\theta} = 0$, and $g_{\varphi\varphi} = \sin^2\theta$. We will use a similar notation for the inverse metric tensor $g$, but with the indices in the upper position. Since $g$ is diagonal, it is easy to compute the inverse metric tensor: $g^{-1}$ has components $g^{\theta\theta} = 1$, $g^{\theta\varphi} = g^{\varphi\theta} = 0$, and $g^{\varphi\varphi} = 1 / \sin^2\theta$.
**Exercise.** Compute the metric arising from the embedding of the 2-sphere in $\mathbb{R}^3$ by stereographic projection:
\begin{equation}
x = \frac{2X}{1+X^2+Y^2}, \qquad
y = \frac{2Y}{1+X^2+Y^2}, \qquad
z = \frac{-1+X^2+Y^2}{1+X^2+Y^2},
\end{equation}
with $(X,Y) \in \mathbb{R}^2$. (Note: Technically, two stereographic projection charts are required to cover the sphere (say, one from the north pole and one from the south), but it can be checked that the metric arising from these projections has the same form in both charts. Therefore, it is enough to consider only one.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Solution:&lt;/em&gt;
\begin{equation} \label{stereographicmetric}
g|_{S^2} = \frac{4}{(1+X^2+Y^2)^2} (dX^2 + dY^2)
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Torus $\mathbb{T}^2$.&lt;/em&gt;
We apply the same procedure as before to the torus $\mathbb{T}^2$ embedded in $\mathbb{R}^3$. The torus (with $R&amp;gt;r$ being the larger and smaller radii, respectively) has coordinates
\begin{equation}
x = (R + r\cos\theta)\cos\varphi, \qquad
y = (R + r\cos\theta)\sin\varphi, \qquad
z = r\sin\theta,
\end{equation}
where $0 \leq \theta, \varphi \leq 2 \pi$. The differentials of these coordinates are then
\begin{align}
dx &amp;amp;= -r\sin\theta\cos\varphi d\theta - (R + r\cos\theta)\sin\varphi d\varphi,\\\&lt;br&gt;
dy &amp;amp;= -r\sin\theta\sin\varphi d\theta + (R + r\cos\theta)\cos\varphi d\varphi,\\\&lt;br&gt;
dz &amp;amp;= r\cos\theta d\theta.
\end{align}
Taking tensor products of each coordinate, we find that
\begin{aligned}
dx^2 &amp;amp;= r^2\sin^2\theta\cos^2\varphi d\theta^2 + (R + r\cos\theta)^2\sin^2\varphi d\varphi^2
+ r(R + r\cos\theta)\sin\theta\cos\varphi\sin\varphi d\theta d\varphi + \left(\cdot\right)d\varphi d\theta,\\\&lt;br&gt;
dy^2 &amp;amp;= r^2\sin^2\theta\sin^2\varphi d\theta^2 + (R + r\cos\theta)^2\cos^2\varphi d\varphi^2 - r(R + r\cos\theta)\sin\theta\sin\varphi\cos\varphi d\theta d\varphi - (\cdot) d\varphi d\theta,\\\&lt;br&gt;
dz^2 &amp;amp;= r^2\cos^2\theta d\theta^2.
\end{aligned}
(We have suppressed the coefficient of the $d\varphi d\theta$ terms, as they are the same as the coefficient of the $d\theta d\varphi$ terms in both cases). Summing, we see that the &amp;ldquo;cross-terms&amp;rdquo; cancel, and what remains can be simplified via trigonometric identities. The metric then takes the form:
\begin{equation}
g\vert_{\mathbb{T}^2} = r^2 d\theta^2 + (R + r\cos\theta)^2 d\varphi^2.
\end{equation}
Thus, the metric is again diagonal, with nonzero components $g_{\theta\theta} = r^2$, $g_{\varphi \varphi} = (R + r\cos\theta)^2$. Since $g$ is diagonal, we can easily compute the inverse metric tensor: $g^{-1}$ has components $g^{\theta\theta} = 1/r^2$, $g^{\varphi\varphi} = 1 / (R + r\cos\theta)^2$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Upper Half Plane $\mathbb{H}$.&lt;/em&gt;
Of course, the metric on a Riemannian manifold need not come from the embedding space: a good example of this is the &lt;em&gt;hyperbolic metric&lt;/em&gt; on the upper half plane $\mathbb{H} :=$ {$(x,y)\in\mathbb{R}^2 : y &amp;gt; 0$}. This metric is defined as
\begin{equation}\label{hyperbolicmetric}
g\vert_{\mathbb{H}} = \frac{dx^2 + dy^2}{y^2} = \frac{|dz|^2}{\vert\text{Im} z\vert^2},
\end{equation}
where here $z = x+iy$. The nonzero components of the metric are $g_{xx} = g_{yy} = \frac{1}{y^2}$, and the nonzero components of the inverse metric tensor are $g^{xx} = g^{yy} = y^2$. The relevance of this metric is that it is the unique metric on the upper half plane that is preserved under conformal automorphisms of the upper half plane (i.e., setting $w(z) = \frac{az+ b}{cz+d}$ with $a,b,c,d$ real, then $\frac{|dz|^2}{|\text{Im} z|^2} = \frac{|dw|^2}{|\text{Im} w|^2}$). We shall not discuss further properties of this metric here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt;
Use the conformal map $w:\mathbb{D} \to \mathbb{H}$, defined by $w(z) = \frac{z+i}{iz+1}$, to pull back the metric above to the unit disc $\mathbb{D} := ${$z | |z| &amp;lt; 1$}. &lt;em&gt;Solution:&lt;/em&gt;
\begin{equation} \label{hyperbolicmetricD}
g\vert_{\mathbb{D}} = \frac{4|dz|^2}{(1-|z|^2)^2}  = \frac{4}{(1-x^2-y^2)^2} (dx^2 + dy^2).
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The 3-sphere $S^3$.&lt;/em&gt;
Consider the 3-sphere $S^3:=${$(x_0,x_1,x_2,x_3) \mid x_0^2 + x_1^2 + x_2^2 + x_3^2 = 1$}. We can parameterize the
$3$-sphere with the coordinates
\begin{equation}
\begin{cases}
x_0 &amp;amp;= \cos \psi,\\\&lt;br&gt;
x_1 &amp;amp;= \sin \psi \cos \theta,\\\&lt;br&gt;
x_2 &amp;amp;= \sin \psi \sin \theta \cos \varphi,\\\&lt;br&gt;
x_3 &amp;amp;= \sin \psi \sin \theta \sin \varphi,\\\&lt;br&gt;
\end{cases}
\end{equation}
Where $0 \leq \psi, \theta \leq \pi$, and $0 \leq \varphi \leq 2 \pi$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt;
Use these coordinates to compute the embedding metric on $S^3$. &lt;em&gt;Solution:&lt;/em&gt;
\begin{equation} \label{3-sphere-metric}
g\vert_{S^3} = d\psi^2 + \sin^2 \psi d\theta^2 + \sin^2 \psi \sin^2 \theta d\varphi^2.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The left-invariant metric on $S^3 \cong SU(2)$ &amp;amp; Hopf coordinates.&lt;/em&gt;
Let us consider new coordinates on the sphere, called the &lt;em&gt;Hopf coordinates&lt;/em&gt;:
\begin{equation}
\begin{cases}
x_0 &amp;amp;= \cos \xi_1 \sin \eta,\\\&lt;br&gt;
x_1 &amp;amp;= \sin \xi_1 \sin \eta,\\\&lt;br&gt;
x_2 &amp;amp;= \cos \xi_2 \cos \eta,\\\&lt;br&gt;
x_3 &amp;amp;= \sin \xi_2 \cos \eta,\\\&lt;br&gt;
\end{cases}
\end{equation}
Where $0 \leq \eta \leq \frac{\pi}{2}$, $0 \leq \xi_1, \xi_2 \leq 2\pi$. It is easy to check that the embedding
metric in these coordinates is
\begin{equation} \label{SU2-metric}
g\vert_{S^3} = d\eta^2 + \sin^2 \eta d\xi_1^2 + \cos^2\eta d\xi_2^2.
\end{equation}
Putting $z_1 = x_0 + ix_1$, $z_2 = x_2 + ix_3$, we can write
\begin{equation}
U(\xi_1,\xi_2,\eta) =
\begin{pmatrix}
e^{i\xi_1}\sin\eta &amp;amp; -e^{-i\xi_2}\cos\eta\\\&lt;br&gt;
e^{i\xi_2}\cos\eta &amp;amp; e^{-i\xi_1}\sin\eta
\end{pmatrix}
=
\begin{pmatrix}
z_1 &amp;amp; -\bar{z}_2\\\&lt;br&gt;
z_2 &amp;amp; \bar{z}_1
\end{pmatrix},
\end{equation}
Which is the generic form of a matrix in $SU(2):=${$U \in GL_2(\mathbb{C}) \mid U^\dagger U = \mathbb{I}, \det U = 1$}. The fact that $(x_0,x_1,x_2,x_3)$ parameterize $S^3$ guarantees that the matrix $U(\xi_1,\xi_2,\eta)$ is unitary, and has unit determinant. This establishes a diffeomorphism between the sphere $S^3$ and the Lie group $SU(2)$. Because of the group structure of $S^3$, we now search for a metric which is invariant under the group action on itself. In fact, we shall see that, up to an overall constant, the unique left-invariant metric on $SU(2)$ is just the usual embedding metric (See the previous example). We make use of the fact that the metric above may be expressed
as $g = |dz_1|^2 + |dz_2|^2$. Let
\begin{equation}
W:= \begin{pmatrix}
w_1 &amp;amp; -\bar{w}_2\\\&lt;br&gt;
w_2 &amp;amp; \bar{w}_1
\end{pmatrix}
\end{equation}
Be another matrix in $SU(2)$, i.e. $|w_1|^2 + |w_2|^2 = 1$. Then, under a left translation,
\begin{equation}
W\cdot Z =
\begin{pmatrix}
w_1 &amp;amp; -\bar{w}_2\\\&lt;br&gt;
w_2 &amp;amp; \bar{w}_1
\end{pmatrix} &lt;br&gt;
\begin{pmatrix}
z_1 &amp;amp; -\bar{z}_2\\\&lt;br&gt;
z_2 &amp;amp; \bar{z}_1
\end{pmatrix}
=&lt;br&gt;
\begin{pmatrix}
w_1z_1-\bar{w}_2z_2 &amp;amp; -\overline{w_2z_1+\bar{w}_1z_2}\\\&lt;br&gt;
w_2z_1+\bar{w}_1z_2 &amp;amp; \overline{w_1z_1-\bar{w}_2z_2},
\end{pmatrix}
\end{equation}
i.e., the translated coordinates are
\begin{align}
\zeta_1 &amp;amp;= w_1z_1-\bar{w}_2z_2,\\\&lt;br&gt;
\zeta_2 &amp;amp;= w_2z_1+\bar{w}_1z_2.
\end{align}
Invariance of the metric under left translations is equivalent to checking that $|dz_1|^2 + |dz_2|^2 =
|d\zeta_1|^2 + |d\zeta_2|^2$. Indeed, we find that
\begin{align}
d\zeta_1 &amp;amp;= w_1dz_1-\bar{w}_2dz_2,\\\&lt;br&gt;
d\zeta_2 &amp;amp;= w_2dz_1+\bar{w}_1dz_2,
\end{align}
so that
\begin{align}
|d\zeta_1|^2 &amp;amp;= |w_1|^2|dz_1|^2 - \bar{w}_1\bar{w}_2dz_2 d\bar{z}_1 -
w_1 w_2 dz_1 d\bar{z}_2 + |w_2|^2 |dz_2|^2,\\\&lt;br&gt;
|d\zeta_2|^2 &amp;amp;= |w_2|^2|dz_1|^2 + \bar{w}_1\bar{w}_2dz_2 d\bar{z}_1 +
w_1 w_2 dz_1 d\bar{z}_2 + |w_1|^2 |dz_2|^2;
\end{align}
adding these expressions yields the identity $|dz_1|^2 + |dz_2|^2 = |d\zeta_1|^2 + |d\zeta_2|^2$.
**Exercise.**
Check that the vector fields
\begin{align}
\sigma_1 &amp;amp;:= \frac{1}{2} \left( -\tan\eta\cos(\xi_1+\xi_2)\frac{\partial}{\partial \xi_1}
+ \cot\eta\cos(\xi_1+\xi_2)\frac{\partial}{\partial \xi_2}+ \sin(\xi_1 + \xi_2) \frac{\partial}{\partial \eta}\right),\\\&lt;br&gt;
\sigma_2 &amp;amp;:= \frac{1}{2} \left(\tan\eta\sin(\xi_1+\xi_2)\frac{\partial}{\partial \xi_1} -
\cot\eta\sin(\xi_1+\xi_2)\frac{\partial}{\partial \xi_2} + \cos(\xi_1 + \xi_2) \frac{\partial}{\partial \eta}\right),\\\&lt;br&gt;
\sigma_3 &amp;amp;:= \frac{1}{2} \left( \frac{\partial}{\partial \xi_1} + \frac{\partial}{\partial \xi_2} \right),
\end{align}
satisfy the commutation relations $[\sigma_i, \sigma_j] = \epsilon_{ijk} \sigma_k$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Schwarzschild metric.&lt;/em&gt;
Riemannian geometry goes hand-in-hand with Einstein&amp;rsquo;s theory of general relativity. One of the first exact solutions to Einstein&amp;rsquo;s field equations is the &lt;em&gt;Schwarzschild solution&lt;/em&gt;:
\begin{equation}\label{Schwarzschildmetric}
g = -\left(1-\frac{r_s}{r}\right) dt^2 + \left(1-\frac{r_s}{r}\right)^{-1} dr^2 + r^2 d\theta^2 + r^2 \sin^2\theta d\varphi^2,
\end{equation}
which (as we shall see) describes a $\delta$-function mass at the origin of an otherwise empty spacetime. $g$ is a pseudo-Riemannian metric on $\mathbb{R}^4$, and has an apparent singularity at $r = r_s$, the &lt;em&gt;Schwarzschild radius&lt;/em&gt;. However, this &amp;ldquo;singularity&amp;rdquo; can be removed by an appropriate change of coordinates (see, for example, 
&lt;a href=&#34;http://www.fulviofrisone.com/attachments/article/486/Wald%20-%20General%20Relativity.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Robert Wald&amp;rsquo;s book&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;2-the-levi-cevita-connection&#34;&gt;$2$. The Levi-Cevita Connection.&lt;/h2&gt;
&lt;p&gt;There are several ways to derive the Levi-Cevita connection (i.e., the unique connection on the tangent bundle which annihilates the metric and has vanishing torsion) from the metric; however, it is not our purpose to derive the Levi-Cevita connection, and so we will present the result here. The components of the connection, called the &lt;em&gt;Christoffel symbols&lt;/em&gt;, have three associated indices: $\Gamma^i_{jk}$; in terms of the metric, the component $\Gamma^i_{jk}$ is given by
\begin{equation} \label{Christoffel}
\Gamma^i_{jk} = \frac{1}{2}\sum_\ell g^{i\ell} \left( \partial_j g_{\ell k} + \partial_k g_{j \ell} -\partial_\ell g_{jk}\right).
\end{equation}
Here, $\partial_j = \frac{\partial}{\partial x_j}$, the derivative with respect to the $j^{th}$ local coordinate. It is worth committing the formula above to memory. Here are a few useful techniques for doing this: Looking closely at the indices, we see that the first two terms are obtained by switching one of the lower indices in $\Gamma^i_{jk}$ with $\ell$, and then differentiating with respect to this variable; note that both terms have a &amp;ldquo;$+$&amp;rdquo; sign in front of them. The last term is obtained by differentiating the component of the metric tensor with indices matching the lower indices of $\Gamma^i_{jk}$ with respect to the summation variable; note that this is the only term with a &amp;ldquo;$-$&amp;rdquo; coefficient. Finally, note that the only place that the upper index appears is in the inverse metric tensor expression.&lt;/p&gt;
&lt;p&gt;Some further remarks about the Christoffel symbols:&lt;/p&gt;
&lt;p&gt;$1$. Note that $\Gamma^i_{jk}$ is symmetric in the indices $j$ and $k$, as a consequence of the fact that $g_{ij} = g_{ji}$.&lt;/p&gt;
&lt;p&gt;$2$. If the metric is diagonal, i.e. $g_{ij} \neq 0 $ only if $i= j$, then $g^{ij}$ is also diagonal, and thus there is no sum over $\ell$ in the above equation: the Christoffel symbols are simply
\begin{equation} \label{simplechrist}
\Gamma^i_{jk} = \frac{1}{2} g^{ii} \left( \partial_j g_{ik} + \partial_k g_{ji} -\partial_i g_{jk}\right);
\end{equation}
This often drastically reduces the number of computations one has to make.
Although, formally speaking, we can now compute the connection, the Christoffel symbols are somewhat difficult to manage; an object with three indices (and which is moreover not tensorial) can be difficult to deal with in general. However, we can improve our situation, at least conceptually. We will think of the connection as a _matrix-valued 1-form_:
\begin{equation}\label{matrix1form}
\Gamma = \sum_k \Gamma_k dx^k,
\end{equation}
where each of the $\Gamma_k$&amp;rsquo;s is a matrix. The ${(ij)}^{th}$ component of the matrix $\Gamma_k$ is given by $(\Gamma_k)^i_j = \Gamma^i_{jk}$. Note that the placement of indices on the left hand side is consistent with that of the right. This definition also allows us to clearly write the Levi-Cevita connection as an operator on vector fields: given a vector field $X$, the connection applied to $X$ can be written as (at least in the local coordinate patch on which we are working)
\begin{equation}
\nabla X = d X + \Gamma X,
\end{equation}
Where $\Gamma$ acts on $X$ as a matrix applied to a vector. As a consistency check, we see that both terms in the above have one upper and one lower index, and are thus of the same type, so that $\nabla X$ is indeed a well-defined and (as we will soon check) tensorial quantity.
Let us begin to demonstrate the utility of this notation. Suppose $(U,x)$, $(V,y)$ are overlapping coordinate charts; consider the change of coordinates $y \to x(y)$. Using our original formulafor the Christoffel symbols, we can (rather tediously) compute $\tilde{\Gamma}^i_{jk}$ in the new coordinates:
\begin{equation}
\tilde{\Gamma}^i_{jk} = \sum_{m,n,p}\left(\frac{\partial x^i}{\partial y^m}\frac{\partial y^n}{\partial x^j}\frac{\partial y^p}{\partial x^k} \Gamma^m_{np} + \frac{\partial^2 y^m}{\partial x^j \partial x^k} \frac{\partial x^i}{\partial y^m} \right).
\end{equation}
Now, adding in the contribution of $dx^k \to \frac{\partial x^k}{\partial y^r} dy^r$, we see that one of the $\frac{\partial y}{\partial x}$ factors
cancels in the expression for $\tilde{\Gamma}^i_{jk} dy^k$.
We can simplify this expression (at least notationally speaking) significantly, Define $\lambda$ to be the matrix-valued function with entries $(\lambda)^i_j = \frac{\partial y^i}{\partial x^j}$. Then, in matrix notation the new expression for the Christoffel symbols reads
\begin{equation}
\tilde{\Gamma} = \lambda \Gamma \lambda^{-1} - d\lambda \cdot\lambda^{-1}.
\end{equation}
The discerning reader will recognize this as what is known as a _gauge transformation_ in physics. This is, of course, no coincidence: a Riemannian manifold can be viewed as a principal- $GL_n(\mathbb{R})$ bundle and (gauge-invariant) connection $\nabla = d + \Gamma$. (If this sentence does not mean anything to you right now, do not worry; it is not relevant to the remainder of this exposition).&lt;/p&gt;
&lt;p&gt;Now, we will check that, indeed, for any vector field $X$, $\nabla X$ is tensorial. Let us use the coordinate transformation of the previous section. Under such a transformation, the vector field $X$ transforms as $\lambda X$. Altogether, we find that, in the new coordinates,
\begin{align}
\tilde{\nabla} \tilde{X} &amp;amp;= \left(d +  \lambda \Gamma \lambda^{-1} - d\lambda \cdot\lambda^{-1}\right) \lambda X\\\
&amp;amp;= d\lambda \cdot X + \lambda dX + \lambda \Gamma X - d\lambda \cdot X \\\&lt;br&gt;
&amp;amp;= \lambda dX + \lambda \Gamma X = \lambda \nabla X,
\end{align}
so that $\nabla X$ is a tensorial quantity, and transforms like a tensor with one additional lower index than $X$.
We conclude this section with some computations carried over from the previous section.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt;&lt;em&gt;The Sphere $S^2$.&lt;/em&gt;
Let us compute the connection coefficients of the Levi-Cevita connection arising from the metric we derived in the previous section. Since the metric is diagonal, we can use formula we derived for the $\Gamma$&amp;rsquo;s for a diagonal metric to compute the Christoffel symbols. Furthermore, since the metric is diagonal, and the only nonconstant component of the metric is $g_{\varphi \varphi}$, we see that the only non-vanishing Christoffel symbols will be those that involve an expression of the form $\partial_\theta g_{\varphi \varphi}$ (since partial derivatives of constants will yield zero). Comparing with diagonal formula, we conclude that the only non-vanishing Christoffel symbols are $\Gamma^{\varphi}_{\varphi\theta} = \Gamma^{\varphi}_{\theta\varphi}$, and $\Gamma^{\theta}_{\varphi\varphi}$. We compute these entries explicitly:
\begin{align}
\Gamma^{\varphi}_{\varphi\theta} = \Gamma^{\varphi}_{\theta\varphi} &amp;amp;= \frac{1}{2} g^{\varphi \varphi} \left( \partial_\varphi g_{\varphi\theta} + \partial_\theta g_{\varphi\varphi} - \partial_\varphi g_{\varphi\theta} \right)
= \frac{1}{2} g^{\varphi \varphi} \left( \partial_\theta g_{\varphi\varphi} \right) = \frac{1}{2} \frac{1}{\sin^2\theta} (2\sin\theta \cos \theta) = \cot\theta, \\\&lt;br&gt;
\Gamma^{\theta}_{\varphi\varphi} &amp;amp;= \frac{1}{2} g^{\theta \theta} \left( \partial_\varphi g_{\theta\varphi} + \partial_\varphi g_{\varphi\theta} - \partial_\theta g_{\varphi\varphi} \right) = -\frac{1}{2} g^{\theta \theta}\left(  \partial_\theta g_{\varphi\varphi} \right) = -\frac{1}{2} (2\sin\theta \cos \theta) = -\sin\theta \cos \theta.
\end{align}
We now write the connection coefficients as a matrix-valued 1-form. Formally, this 1-form should look like
\begin{equation}
\Gamma = \Gamma_\theta d\theta+ \Gamma_\varphi d\varphi=
\begin{pmatrix} \Gamma^\theta_{\theta \theta} &amp;amp;  \Gamma^\theta_{\varphi\theta}\\\ \Gamma^\varphi_{\theta\theta} &amp;amp; \Gamma^\varphi_{\varphi\theta} \end{pmatrix}
d \theta +
\begin{pmatrix}  \Gamma^\theta_{\theta \varphi} &amp;amp;  \Gamma^\theta_{\varphi\varphi}\\\ \Gamma^\varphi_{\theta\varphi} &amp;amp; \Gamma^\varphi_{\varphi\varphi} \end{pmatrix}
d\varphi.
\end{equation}
Using the expressions we found earlier for the Christoffel symbols, we find that $\Gamma$ explicitly takes the form
\begin{equation} \label{sphereconn}
\Gamma = \Gamma_\theta d\theta + \Gamma_\varphi d\varphi=
\begin{pmatrix} 0 &amp;amp; 0 \\\ 0 &amp;amp; \cot \theta \end{pmatrix}
d \theta +
\begin{pmatrix}  0 &amp;amp;  -\sin\theta \cos\theta \\\ \cot\theta&amp;amp; 0 \end{pmatrix}
d\varphi.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt;
Compute the connection form of the stereographic metric on the sphere.
&lt;em&gt;Solution:&lt;/em&gt;
Set $\rho(X,Y) = 1 + X^2 + Y^2$. Then the connection form is
\begin{equation}\label{stereographicconn}
\Gamma = \Gamma_X dX + \Gamma_Y dY =
\frac{2}{\rho} \begin{pmatrix} -X &amp;amp; -Y \\\ Y &amp;amp; -X \end{pmatrix}
d X +
\frac{2}{\rho} \begin{pmatrix}  -Y &amp;amp;  X \\\ -X &amp;amp; -Y \end{pmatrix}
dY.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Torus $\mathbb{T}^2$.&lt;/em&gt;
Using the explicit expression for the metric on the torus, and the formula for the Christoffel symbols of a diagonal metric, we can compute the coefficients of the Levi-Cevita connection. Let us first determine all nonzero Christoffel symbols. Since the only non-constant entry in the metric is $g_{\varphi\varphi} = (R + r\cos\theta)^2$, and this coefficient depends only on the variable $\theta$, we see that the only nonzero Christoffel symbols will be those which contain the term $\partial_{\theta} g_{\varphi \varphi}$. There are precisely three of these: $\Gamma^\varphi_{\varphi \theta} = \Gamma^\varphi_{\theta\varphi}$, and $\Gamma^{\theta}_{\varphi \varphi}$. We compute these terms explicitly:
\begin{align}
\Gamma^\varphi_{\varphi \theta} = \Gamma^\varphi_{\theta\varphi} &amp;amp;= \frac{1}{2} g^{\varphi \varphi} \left( \partial_\varphi g_{\varphi \theta} + \partial_\theta g_{\varphi \varphi} - \partial_\varphi g_{\varphi \theta}\right) = \frac{1}{2} g^{\varphi \varphi} \left(\partial_\theta g_{\varphi \varphi}\right) = \frac{-r\sin\theta}{R + r\cos\theta},\\\&lt;br&gt;
\Gamma^{\theta}_{\varphi \varphi} &amp;amp;= \frac{1}{2}g^{\theta\theta} \left( \partial_\varphi g_{\theta \varphi} + \partial_\varphi g_{\varphi \theta} - \partial_\theta g_{\varphi\varphi}\right) = \frac{(R + r \cos\theta)}{r} \sin\theta.
\end{align}
Now, writing the connection as a matrix-valued 1-form, we find that
\begin{equation}\label{torusconn}
\Gamma = \Gamma_\theta d\theta + \Gamma_\varphi d\varphi=
\begin{pmatrix} 0 &amp;amp; 0 \\\ 0 &amp;amp; \frac{-r\sin\theta}{R + r\cos\theta} \end{pmatrix}
d \theta +
\begin{pmatrix}  0 &amp;amp; \frac{(R + r \cos\theta)}{r} \sin\theta\\\  \frac{-r\sin\theta}{R + r\cos\theta}&amp;amp; 0 \end{pmatrix}
d\varphi.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Upper Half Plane $\mathbb{H}$.&lt;/em&gt;
We now compute the Christoffel symbols of the hyperbolic metric on the upper half plane. Note that only Christoffel symbols containing the terms $\partial_y g_{xx}$ or $\partial_y g_{yy}$ have a chance of being nonzero. Thus, the nonzero Christoffel symbols are $\Gamma^x_{yx} = \Gamma^x_{xy}$, $\Gamma^y_{xx}$, and $\Gamma^y_{yy}$. Since the metric is diagonal, we can again use the nice formula we derived to compute the Christoffel symbols: we find that
\begin{align}
\Gamma^x_{yx} = \Gamma^x_{xy} &amp;amp;= \frac{1}{2} g^{xx}\left(\partial_y g_{xx} + \partial_x g_{yx} - \partial_x g_{yx}\right) = \frac{1}{2} g^{xx}\left(\partial_y g_{xx}\right) = -1/y, \\\&lt;br&gt;
\Gamma^y_{xx} &amp;amp;= \frac{1}{2} g^{yy}\left(\partial_x g_{yx} + \partial_x g_{xy} - \partial_y g_{xx}\right) = -\frac{1}{2} g^{yy}\left( \partial_y g_{xx}\right) = 1/y,\\\&lt;br&gt;
\Gamma^y_{yy} &amp;amp;= \frac{1}{2} g^{yy}\left(\partial_y g_{yy} + \partial_y g_{yy} - \partial_y g_{yy}\right) =
\frac{1}{2} g^{yy}\left(\partial_y g_{yy}\right) = -1/y.
\end{align}
Written as a matrix-valued 1-form, the connection takes the form
\begin{equation}\label{halfplaneconn}
\Gamma = \Gamma_x dx + \Gamma_y dy = \begin{pmatrix}  0 &amp;amp; -1/y \\\  1/y&amp;amp; 0 \end{pmatrix}  dx + \begin{pmatrix}  -1/y &amp;amp; 0 \\\  0 &amp;amp; -1/y \end{pmatrix} dy.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt; Compute the connection form of the hyperbolic metric on the disc. &lt;em&gt;Solution:&lt;/em&gt; Set $\sigma(x,y) = 1 - x^2 - y^2$; then the connection form is given as
\begin{equation}
\Gamma = \Gamma_x dx + \Gamma_y dy = \frac{2}{\sigma} \begin{pmatrix} x &amp;amp; y \\\ -y &amp;amp; x \end{pmatrix} dx + \frac{2}{\sigma} \begin{pmatrix}  y &amp;amp;  -x \\\ x &amp;amp; y \end{pmatrix} dy.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The 3-sphere $S^3$.&lt;/em&gt;
We compute the connection form from the metric on the 3-sphere we derived previously. Since the only nonzero components of the
metric are $g_{\psi\psi} = 1$, $g_{\theta\theta} = \sin^2\psi$, and $g_{\varphi\varphi} = \sin^2\psi\sin^2\theta$,
the only nonvanishing derivatives of the metric will be $\partial_\psi g_{\theta \theta}$, $\partial_{\psi} g_{\varphi\varphi}$,
and $\partial_{\theta}g_{\varphi \varphi}$. Thus, we must compute the $9$ nontrivial Christoffel symbols:
$\Gamma^{\psi}_{\theta\theta}$, $\Gamma^{\theta}_{\theta \psi} = \Gamma^{\theta}_{\psi \theta}$,
$\Gamma^{\psi}_{\varphi \varphi}$, $\Gamma^{\varphi}_{\psi \varphi} = \Gamma^{\varphi}_{\varphi \psi}$,
$\Gamma^{\theta}_{\varphi \varphi}$, and $\Gamma^{\varphi}_{\theta \varphi} = \Gamma^{\varphi}_{\varphi\theta}$.
By direct computation, we find that
\begin{align}
\Gamma^{\psi}_{\theta\theta} &amp;amp;= -\sin\psi \cos \psi,\\\&lt;br&gt;
\Gamma^{\theta}_{\theta \psi} &amp;amp;= \Gamma^{\theta}_{\psi \theta} = \cot \psi,\\\
\Gamma^{\psi}_{\varphi \varphi} &amp;amp;= -\sin \psi \cos \psi \sin^2\theta,\\\&lt;br&gt;
\Gamma^{\varphi}_{\psi \varphi} &amp;amp;= \Gamma^{\varphi}_{\varphi \psi} = \cot \theta,\\\&lt;br&gt;
\Gamma^{\theta}_{\varphi \varphi} &amp;amp;= -\sin \theta \cos \theta,\\\&lt;br&gt;
\Gamma^{\varphi}_{\theta \varphi} &amp;amp;= \Gamma^{\varphi}_{\varphi\theta} = \cot\theta.
\end{align}
The connection form is thus
\begin{equation}\label{3-sphere-conn}
\Gamma = \begin{pmatrix} 0 &amp;amp; 0 &amp;amp;0\\\ 0 &amp;amp; \cot\psi &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; \cot \psi \end{pmatrix} d\psi
+ \begin{pmatrix} 0 &amp;amp; -\sin\psi\cos\psi &amp;amp;0\\\  \cot\psi &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; \cot \theta \end{pmatrix} d\theta
+ \begin{pmatrix} 0 &amp;amp; 0 &amp;amp; -\sin\psi\cos\psi\sin^2\theta\\\  0 &amp;amp; 0 &amp;amp; -\sin\theta\cos\theta\\\  \cot \psi &amp;amp;  \cot \theta &amp;amp; 0 \end{pmatrix} d\varphi
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The left-invariant metric on $S^3 \cong SU(2)$ &amp;amp; Hopf coordinates.&lt;/em&gt;
Recall the invariant metric on $S^3$ had entries $g_{\eta \eta} = 1$, $g_{\xi_1\xi_1} = \sin^2\eta$,
and $g_{\xi_2\xi_2} = \cos^2\eta$. Thus, the only non-vanishing derivatives of the metric tensor will be
$\partial_{\eta} g_{\xi_1 \xi_1}$ and $\partial_{\eta} g_{\xi_2 \xi_2}$; consequentially, there are only $6$
non-vanishing connection coefficients: $\Gamma^{\eta}_{\xi_1\xi_1}$, $\Gamma^{\xi_1}_{\eta \xi_1} =
\Gamma^{\xi_1}_{\xi_1 \eta}$, $\Gamma^{\eta}_{\xi_2\xi_2}$, and $\Gamma^{\xi_2}_{\eta \xi_2} =
\Gamma^{\xi_2}_{\xi_2 \eta}$. We compute that:
\begin{align*}
\Gamma^{\eta}_{\xi_1 \xi_1} &amp;amp;= -\cos\eta \sin\eta,\\\&lt;br&gt;
\Gamma^{\xi_1}_{\eta \xi_1} &amp;amp;=  \Gamma^{\xi_1}_{\xi_1 \eta} = \cot \eta,\\\&lt;br&gt;
\Gamma^{\eta}_{\xi_2 \xi_2} &amp;amp;= \cos\eta \sin\eta,\\\&lt;br&gt;
\Gamma^{\xi_2}_{\eta \xi_2} &amp;amp;=  \Gamma^{\xi_2}_{\xi_2 \eta} = -\tan \eta.
\end{align*}
The connection form is thus
\begin{equation} \label{SU2-conn}
\Gamma = \begin{pmatrix} 0 &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; \cot \eta &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; -\tan \eta \end{pmatrix}d\eta + \begin{pmatrix} 0 &amp;amp; -\cos\eta \sin \eta &amp;amp; 0\\\ \cot\eta &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; 0 \end{pmatrix}d\xi_1 + \begin{pmatrix} 0 &amp;amp; 0 &amp;amp; \cos\eta \sin \eta\\\ 0 &amp;amp; 0 &amp;amp; 0\\\ -\tan\eta &amp;amp; 0 &amp;amp; 0 \end{pmatrix}d\xi_2.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Schwarzschild metric.&lt;/em&gt;
We now compute the connection form from the Schwarzshield metric. By inspection, we see that the only nonvanishing derivatives of the metric are: $\partial_r g_{tt}$, $\partial_r g_{rr}$, $\partial_r g_{\theta\theta}$, $\partial_r g_{\varphi \varphi}$, and $\partial_\theta g_{\varphi \varphi}$. Since the metric is diagonal, the only non-vanishing Christoffel symbols are: $\Gamma^r_{tt}$, $\Gamma^t_{rt} = \Gamma^t_{tr}$, $\Gamma^r_{rr}$, $\Gamma^r_{\theta\theta}$, $\Gamma^\theta_{r \theta} = \Gamma^\theta_{\theta r}$, $\Gamma^r_{\varphi\varphi}$, $\Gamma^\varphi_{r \varphi} = \Gamma^\varphi_{\varphi r}$, $\Gamma^\theta_{\varphi \varphi}$, and finally $\Gamma^\varphi_{\theta \varphi} = \Gamma^\varphi_{\varphi \theta}$. These quantities are computed below:
\begin{align}
\Gamma^r_{tt} &amp;amp;=  -\frac{1}{2}g^{rr} \left(\partial_r g_{tt}\right) = \frac{1}{2}\frac{r_s}{r^2}\left(1-\frac{r_s}{r}\right),\\\&lt;br&gt;
\Gamma^t_{rt} = \Gamma^t_{tr} &amp;amp;= \frac{1}{2}g^{tt} \left(\partial_r g_{tt}\right) = \frac{1}{2}\frac{r_s}{r^2}\left(1-\frac{r_s}{r}\right)^{-1},\\\&lt;br&gt;
\Gamma^r_{rr} &amp;amp;= \frac{1}{2}g^{rr}\left(\partial_r g_{rr}\right) = -\frac{1}{2}\frac{r_s}{r^2} \left(1-\frac{r_s}{r}\right)^{-1},\\\&lt;br&gt;
\Gamma^r_{\theta\theta} &amp;amp;= -\frac{1}{2}g^{rr} \left(\partial_r g_{\theta\theta}\right) = -r\left(1 - \frac{r_s}{r}\right),\\\&lt;br&gt;
\Gamma^\theta_{r \theta} = \Gamma^\theta_{\theta r} &amp;amp;= \frac{1}{2}g^{\theta\theta} \left(\partial_r g_{\theta\theta}\right) = \frac{1}{r},\\\&lt;br&gt;
\Gamma^r_{\varphi\varphi} &amp;amp;= -\frac{1}{2}g^{rr} \left(\partial_r g_{\varphi\varphi}\right) = -r\sin^2\theta\left(1-\frac{r_s}{r}\right), \\\&lt;br&gt;
\Gamma^\varphi_{r \varphi} = \Gamma^\varphi_{\varphi r} &amp;amp;= \frac{1}{2}g^{\varphi\varphi} \left(\partial_r g_{\varphi\varphi}\right) = \frac{1}{r},\\\&lt;br&gt;
\Gamma^\theta_{\varphi \varphi} &amp;amp;= -\frac{1}{2}g^{\theta\theta} \left(\partial_\theta g_{\varphi\varphi}\right) = -\sin\theta\cos\theta,\\\&lt;br&gt;
\Gamma^\varphi_{\theta \varphi} = \Gamma^\varphi_{\varphi \theta} &amp;amp;= \frac{1}{2}g^{\varphi\varphi} \left(\partial_\theta g_{\varphi\varphi}\right) = \cot\theta.\\\&lt;br&gt;
\end{align}
Therefore, in matrix form, the Schwarzschild connection looks like
\begin{equation}\label{Schwarzschildconn}
\begin{split}
\Gamma&amp;amp;=\begin{pmatrix}  0 &amp;amp; \frac{1}{2}\frac{r_s}{r^2}\left(1-\frac{r_s}{r}\right)^{-1} &amp;amp; 0 &amp;amp; 0 \\\ \frac{1}{2}\frac{r_s}{r^2}\left(1-\frac{r_s}{r}\right) &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix} dt +
\begin{pmatrix}  \frac{1}{2}\frac{r_s}{r^2}\left(1-\frac{r_s}{r}\right)^{-1} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; -\frac{1}{2}\frac{r_s}{r^2} \left(1-\frac{r_s}{r}\right)^{-1} &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; \frac{1}{r} &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \frac{1}{r}\end{pmatrix} dr \\\&lt;br&gt;
&amp;amp;+ \begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; -r\left(1 - \frac{r_s}{r}\right) &amp;amp; 0 \\\ 0 &amp;amp; \frac{1}{r} &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cot\theta\end{pmatrix} d\theta +
\begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -r\sin^2\theta\left(1-\frac{r_s}{r}\right) \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\sin\theta\cos\theta \\\ 0 &amp;amp; \frac{1}{r} &amp;amp; \cot\theta &amp;amp; 0\end{pmatrix} d\varphi.
\end{split}
\end{equation}&lt;/p&gt;
&lt;h2 id=&#34;3-the-riemann-tensor&#34;&gt;$3$. The Riemann Tensor.&lt;/h2&gt;
&lt;p&gt;The next object we would like to be able to compute is the Riemann curvature tensor. Seemingly, we are in a much worse situation than before, as we now have to describe an object with 4 indices. In fact, this will turn out to be manageable: just as we expressed the connection coefficients as a matrix-valued 1-form, we will express the Riemann tensor as a matrix-valued 2-form. Contrary to the notation popular in Riemannian geometry, we will denote the Riemann tensor by $\Omega$, and establish a correspondence to the usual notation $R^i_{jkl}$. As usual, the Riemann tensor is defined as $\Omega := \nabla \circ \nabla$, the connection applied to itself. In our formalism, computing the Riemann tensor amounts to the following computation. Let $X$ be any vector field; then
\begin{align}
\Omega X&amp;amp; = (\nabla \circ \nabla) X = \nabla(dX + \Gamma X)
= d(dX + \Gamma X) + \Gamma (dX + \Gamma X)\\\&lt;br&gt;
&amp;amp;=d(dX) + d\Gamma \cdot X - \Gamma dX + \Gamma dX + (\Gamma \wedge \Gamma) X \\\&lt;br&gt;
&amp;amp;= (d\Gamma + \Gamma \wedge \Gamma)X,
\end{align}
Since $d^2 = 0$. Therefore, locally, we can write the curvature tensor as the matrix-valued 2-form $\Omega = d\Gamma + \Gamma \wedge \Gamma$ _Note: $\Gamma \wedge \Gamma$ is nonzero in general, since $\Gamma$ has matrix coefficients. This will be made apparent in the examples._ This is consistent with the Riemann tensor having 1 upper and 3 lower indices (1 upper and 1 lower contributing to the matrix coefficient, and the remaining 2 lower contributing to the 2-form). Write $\Omega$ as $\Omega = \Omega_{kl} dx^k \wedge dx^l$, where each $\Omega_{kl}$ is a matrix. In the usual notation of the Riemann tensor, the $(ij)^{th}$ component of the matrix $\Omega_{kl}$ is given by $(\Omega_{kl})^i_j = R^i_{jkl}$. As an immediate consequence, we see that the Riemann tensor is antisymmetric in two of its indices.&lt;/p&gt;
&lt;p&gt;Furthermore, this notation allows for an almost trivial proof of the second Bianchi identity: Note that $\Omega \nabla = ${$(d+\Gamma)(d+\Gamma)$}$(d+\Gamma) = (d+\Gamma)${$(d+\Gamma)(d+\Gamma)$} $= \nabla \Omega$. Applying this identity to a vector field $X$, we see that $\Omega \nabla X = \nabla(\Omega X) = \Omega \nabla X + (\nabla \Omega) X$, implying that $\nabla \Omega = 0$.&lt;/p&gt;
&lt;p&gt;The Riemann tensor is now a more manageable quantity, and we now show by direct computation (through the examples of the previous sections) that working with it is not too difficult.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Sphere $S^2$.&lt;/em&gt;
We now compute the Riemann tensor of the sphere using the connection form we found in the last section. We must compute two quantities: $d\Gamma$ and $\Gamma\wedge\Gamma$. Let us begin by computing $d\Gamma$: since $\Gamma = \Gamma_\theta d\theta + \Gamma_\varphi d\varphi$, we find that $d \Gamma = \left( \partial_\theta \Gamma_\varphi - \partial_\varphi \Gamma_\theta\right) d\theta \wedge d\varphi$. Now, since $\Gamma_\theta$ is independent of $\varphi$, we see that this expression simplifies to $d\Gamma = \partial_\theta \Gamma_\varphi d\theta \wedge d\varphi$. Explicitly (i.e., applying this prescription to the connection on the sphere we derived), we find that
\begin{equation}\label{dgammasphere}
d\Gamma = \partial_\theta\begin{pmatrix}  0 &amp;amp; -\sin\theta \cos\theta \\\  \cot\theta&amp;amp; 0 \end{pmatrix}
d\theta \wedge d\varphi = \begin{pmatrix}  0 &amp;amp;  \sin^2\theta - \cos^2\theta\\\ -\csc^2\theta&amp;amp; 0 \end{pmatrix}
d\theta \wedge d\varphi.
\end{equation}
Now, we are left to compute $\Gamma\wedge\Gamma$. We find that $\Gamma\wedge\Gamma = \left(\Gamma_\theta d\theta + \Gamma_\varphi d\varphi\right)\wedge \left(\Gamma_\theta d\theta + \Gamma_\varphi d\varphi\right) = [\Gamma_\theta,\Gamma_\varphi] d\theta\wedge d\varphi$, where $[\cdot,\cdot]$ denotes the matrix commutator. After some simple matrix algebra, one finds that
\begin{equation}\label{gammawedgesphere}
\Gamma\wedge\Gamma = [\Gamma_\theta,\Gamma_\varphi] d\theta\wedge d\varphi = \begin{pmatrix}  0 &amp;amp; \cos^2\theta \\\ \cot^2\theta &amp;amp; 0 \end{pmatrix} d\theta \wedge d\varphi.
\end{equation}
Combining these results, we find that
\begin{equation}\label{spherecurvature}
\Omega = d\Gamma + \Gamma \wedge \Gamma = \begin{pmatrix}  0 &amp;amp; \sin^2\theta \\\ -1 &amp;amp; 0 \end{pmatrix} d\theta \wedge d\varphi.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt;
Compute the curvature form of the sphere with stereographic connection.
&lt;em&gt;Solution:&lt;/em&gt; Again, setting $\rho(X,Y) = 1 + X^2 + Y^2$, the curvature tensor takes the form
\begin{equation} \label{stereographiccurvature}
\Omega = \begin{pmatrix}  0 &amp;amp; 4/\rho \\\ -4/\rho &amp;amp; 0 \end{pmatrix} dX \wedge dY.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt;&lt;em&gt;The Torus $\mathbb{T}^2$.&lt;/em&gt;
Continuing the example of the torus, we now compute the Riemann tensor on the torus from the connection. We separately compute $d\Gamma$ and $\Gamma\wedge\Gamma$. Now, $d\Gamma = \left( \partial_\theta \Gamma_\varphi - \partial_\varphi \Gamma_\theta \right) d\theta\wedge d\varphi = \partial_\theta \Gamma_\varphi d\theta\wedge d\varphi$, since $\Gamma_\theta$ is independent of $\varphi$. Thus, we find that
\begin{equation}\label{torusdgamma}
d\Gamma =  \partial_\theta \Gamma_\varphi d\theta\wedge d\varphi = \partial_\theta \begin{pmatrix}  0 &amp;amp; \frac{(R + r \cos\theta)}{r}\sin\theta \\\  \frac{-r\sin\theta}{R + r\cos\theta}&amp;amp; 0 \end{pmatrix}
d\theta \wedge d\varphi = \begin{pmatrix}  0 &amp;amp; \frac{\cos\theta(R+r\cos\theta)}{r}-\sin^2\theta \\\  \frac{-r(r+R\cos\theta)}{(R + r\cos\theta)^2}&amp;amp; 0 \end{pmatrix}
d\theta \wedge d\varphi.
\end{equation}
Furthermore, we find that $\Gamma\wedge\Gamma = \left(\Gamma_\theta d\theta + \Gamma_\varphi d\varphi\right)\wedge \left(\Gamma_\theta d\theta + \Gamma_\varphi d\varphi\right) = [\Gamma_\theta,\Gamma_\varphi] d\theta\wedge d\varphi$; after some computations, we see that this simplifies to
\begin{equation}\label{torusgammawedge}
\Gamma\wedge\Gamma = [\Gamma_\theta,\Gamma_\varphi] d\theta\wedge d\varphi = \begin{pmatrix}  0 &amp;amp; \sin^2\theta \\\  \frac{r^2 \sin^2\theta}{(R+ r\cos\theta)^2} &amp;amp; 0 \end{pmatrix}
d\theta \wedge d\varphi.
\end{equation}
Combining these results, we obtain the curvature tensor:
\begin{equation} \label{toruscurvature}
\Omega = d\Gamma + \Gamma\wedge\Gamma =  \begin{pmatrix}  0 &amp;amp; \frac{\cos\theta(R+r\cos\theta)}{r} \\\  -\frac{r \cos\theta}{R+ r\cos\theta} &amp;amp; 0 \end{pmatrix} d\theta \wedge d\varphi.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt;&lt;strong&gt;The Upper Half Plane $\mathbb{H}$.&lt;/strong&gt;
We now find the Riemann tensor on the upper half plane endowed with the hyperbolic metric; as before, we must compute $d\Gamma$ and $\Gamma \wedge \Gamma$. Now, $d\Gamma = \left(\partial_x \Gamma_y - \partial_y \Gamma_x\right) dx\wedge dy = -\partial_y \Gamma_x dx\wedge dy$, since $\Gamma_y$ is independent of $x$. Therefore:
\begin{equation}\label{dgammaHP}
d\Gamma = -\partial_y \Gamma_x dx\wedge dy = -\partial_y \begin{pmatrix}  0 &amp;amp; -1/y \\\  1/y&amp;amp; 0 \end{pmatrix}  dx\wedge dy = \begin{pmatrix}  0 &amp;amp; -1/y^2 \\\  1/y^2 &amp;amp; 0 \end{pmatrix}  dx\wedge dy.
\end{equation}
Furthermore, we must compute $\Gamma\wedge\Gamma = [\Gamma_x,\Gamma_y] dx\wedge dy$. We find that:
\begin{equation}
\Gamma\wedge\Gamma = [\Gamma_x,\Gamma_y] dx\wedge dy = 0.
\end{equation}
(This is due to the fact that $\Gamma_y$ is a multiple of the identity matrix). Therefore, the curvature tensor is
\begin{equation}
\Omega = d\Gamma + \Gamma\wedge\Gamma = \begin{pmatrix}  0 &amp;amp; -1/y^2 \\\  1/y^2 &amp;amp; 0 \end{pmatrix}  dx\wedge dy.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt;
Compute the curvature form of the disc with the hyperbolic connection. &lt;em&gt;Solution:&lt;/em&gt;
Setting $\sigma(x,y) = 1 - x^2 - y^2$, the curvature form is
\begin{equation}\label{hyperbolicD}
\Omega = \begin{pmatrix}  0 &amp;amp; -4/\sigma^2 \\\  4/\sigma^2 &amp;amp; 0 \end{pmatrix}  dx\wedge dy.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt; &lt;em&gt;The 3-sphere $S^3$.&lt;/em&gt;
Using the first expression for the connection on $S^3$, compute the Riemann tensor.
&lt;em&gt;Solution:&lt;/em&gt;
\begin{equation} \label{3-sphere-curv}
\Omega = \begin{pmatrix} 0 &amp;amp;\sin^2\psi &amp;amp; 0\\\ -1 &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix}d\psi\wedge d\theta
+\begin{pmatrix} 0 &amp;amp; 0 &amp;amp; \sin^2\psi \sin^2\theta \\\ 0 &amp;amp; 0 &amp;amp; 0\\\ -1 &amp;amp; 0 &amp;amp; 0\end{pmatrix}d\psi\wedge d\varphi
+\begin{pmatrix} 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; \sin^2\psi \sin^2\theta\\\ 0 &amp;amp; \sin^2\psi &amp;amp; 0\end{pmatrix}d\theta\wedge d\varphi.
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt; &lt;em&gt;The left-invariant metric on $S^3 \cong SU(2)$ &amp;amp; Hopf coordinates.&lt;/em&gt;
Using the expression for the invariant connection on $SU(2)$, compute the Riemann tensor.
&lt;em&gt;Solution:&lt;/em&gt;
\begin{equation}\label{SU2-curv}
\Omega = \begin{pmatrix}0 &amp;amp; \sin^2\eta &amp;amp; 0\\\ -1 &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix}d\eta\wedge d\xi_1
+ \begin{pmatrix}0 &amp;amp; 0 &amp;amp; \cos^2\eta\\\ 0 &amp;amp; 0 &amp;amp; 0\\\ -1 &amp;amp; 0 &amp;amp; 0\end{pmatrix}d\eta\wedge d\xi_2
+ \begin{pmatrix}0 &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; \cos^2\eta\\\ 0 &amp;amp; -\sin^2\eta &amp;amp; 0\end{pmatrix} d\xi_1\wedge d\xi_2
\end{equation}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Schwarzschild metric.&lt;/em&gt;
Using the Schwarzschild connection, we can compute the curvature form. We begin by computing $d\Gamma$; we have that
$d\Gamma = - \partial_r \Gamma_t dt\wedge dr + \partial_r \Gamma_\theta  dr\wedge d\theta + \partial_r \Gamma_\varphi dr\wedge d\varphi + \partial_\theta \Gamma_\theta d\theta \wedge d\varphi$. Using the expression we derived, we find that:
\begin{align}
- \partial_r \Gamma_t dt\wedge dr  &amp;amp;= - \partial_r \begin{pmatrix}  0 &amp;amp; \frac{1}{2}\frac{r_s}{r^2}\left(1-\frac{r_s}{r}\right)^{-1} &amp;amp; 0 &amp;amp; 0 \\\ \frac{1}{2}\frac{r_s}{r^2}\left(1-\frac{r_s}{r}\right) &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix} dt\wedge dr =\begin{pmatrix}  0 &amp;amp; \frac{r_s(2r-r_s)}{2r^2(r-r_s)^2} &amp;amp; 0 &amp;amp; 0 \\\ \frac{r_s(2r-3r_s)}{2r^4} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix} dt\wedge dr, \\\&lt;br&gt;
\partial_r \Gamma_\theta  dr\wedge d\theta &amp;amp;= \partial_r \begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; -r\left(1 - \frac{r_s}{r}\right) &amp;amp; 0 \\\ 0 &amp;amp; \frac{1}{r} &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cot\theta\end{pmatrix}  dr\wedge d\theta = \begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \\\ 0 &amp;amp; -\frac{1}{r^2} &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix}  dr\wedge d\theta,\\\&lt;br&gt;
\partial_r \Gamma_\varphi dr\wedge d\varphi &amp;amp;= \partial_r \begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -r\sin^2\theta\left(1-\frac{r_s}{r}\right) \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\sin\theta\cos\theta \\\ 0 &amp;amp; \frac{1}{r} &amp;amp; \cot\theta &amp;amp; 0\end{pmatrix}dr\wedge d\varphi = \begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\sin^2\theta \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; -\frac{1}{r^2} &amp;amp; 0 &amp;amp; 0\end{pmatrix} dr\wedge d\varphi,\\\&lt;br&gt;
\partial_\theta \Gamma_\varphi d\theta \wedge d\varphi &amp;amp;= \partial_\theta\begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -r\sin^2\theta\left(1-\frac{r_s}{r}\right) \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\sin\theta\cos\theta \\\ 0 &amp;amp; \frac{1}{r} &amp;amp; \cot\theta &amp;amp; 0\end{pmatrix} = \begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -2r\sin\theta\cos\theta\left(1-\frac{r_s}{r}\right) \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \sin^2\theta-\cos^2\theta \\\ 0 &amp;amp; 0 &amp;amp; -\csc^2\theta &amp;amp; 0\end{pmatrix} d\theta \wedge d\varphi.
\end{align}
We now must compute $\Gamma \wedge \Gamma$. It is easily shown that $\Gamma\wedge\Gamma = [\Gamma_t,\Gamma_r]dt\wedge dr [\Gamma_t,\Gamma_\theta]dt\wedge d\theta + [\Gamma_t,\Gamma_\varphi]dt\wedge d\varphi + [\Gamma_r,\Gamma_\theta]dr\wedge d\theta + [\Gamma_r,\Gamma_\varphi]dr\wedge d\varphi + [\Gamma_\theta,\Gamma_\varphi]d\theta \wedge d\varphi$. Again, using the connection, and some (rather tedious, but still elementary) matrix algebra, we can eventually compute the Riemann tensor to be:
\begin{equation}
\begin{split}
\Omega &amp;amp;= \begin{pmatrix}  0 &amp;amp; \frac{r_s}{r^2(r-r_s)} &amp;amp; 0 &amp;amp; 0 \\\ \frac{r_s(r-r_s)}{r^4} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix} dt\wedge dr
+ \begin{pmatrix}  0 &amp;amp; 0 &amp;amp; -\frac{r_s}{2r} &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ \frac{r_s(r-r_s)}{2r^4} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix} dt\wedge d\theta\\\&lt;br&gt;
&amp;amp;+\begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\frac{r_s \sin^2\theta}{2r} \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ \frac{r_s(r-r_s)}{2r^4} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix} dt\wedge d\varphi
+\begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; -\frac{r_s}{2r} &amp;amp; 0 \\\ 0 &amp;amp; \frac{r_s}{r^2(r-r_s)} &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{pmatrix} dr\wedge d\theta\\\&lt;br&gt;
&amp;amp;+\begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\frac{r_s\sin^2\theta}{2r} \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; \frac{r_s}{2r^2(r-r_s)} &amp;amp; 0 &amp;amp; 0\end{pmatrix} dr\wedge d\varphi
+\begin{pmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\frac{r_s\sin^2\theta}{r} \\\ 0 &amp;amp; 0 &amp;amp; -\frac{r_s}{r} &amp;amp; 0\end{pmatrix} d\theta\wedge d\varphi
\end{split}
\end{equation}&lt;/p&gt;
&lt;h2 id=&#34;4-the-ricci-and-scalar-curvatures&#34;&gt;$4$. The Ricci and scalar curvatures.&lt;/h2&gt;
&lt;p&gt;Commonly, problems in geometry require one to compute derived quantities of the Riemann tensor. Two of the most important are the Ricci and scalar curvatures: the Ricci curvature is defined to be the trace of the Riemann tensor:
\begin{equation} \label{Ricci}
R_{ij} = \sum_k R^k_{ikj}.
\end{equation}
This quantity is symmetric in its remaining indices. We will carry on our examples from the previous section to make the computations here transparent. Finally, the scalar curvature is defined to be the contraction of both indices the Ricci tensor:
\begin{equation}
R = \sum_{i,j} g^{ij}R_{ij}.
\end{equation}
Let us compute these quantities for the examples from the previous sections.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt;&lt;em&gt;The Sphere $S^2$.&lt;/em&gt;
Using equation the Riemann tensor we computed for $S^2$, we can compute the Ricci and scalar curvatures. We compute each component of the Ricci tensor individually: let us begin with $R_{\theta \theta}$. By equation the expression we have for the Ricci tensor, we have that $R_{\theta \theta} = R^{\theta}_{\theta \theta\theta} + R^{\varphi}_{\theta \varphi\theta} = R^{\varphi}_{\theta \varphi \theta}$, since the Riemann tensor is antisymmetric in the last two indices (it is a matrix-valued 2-form). Write $\Omega = \Omega_{kl} dx^k \wedge dx^l$. Since $(\Omega_{kl})^i_j = R^i_{jkl}$, and using our equation for $\Omega$, we see that $R^{\varphi}_{\theta \varphi\theta} = 1$. Similarly, we compute $R_{\varphi\varphi} = R^{\theta}_{\varphi \theta\varphi} + R^{\varphi}_{\varphi \varphi\varphi} = R^{\theta}_{\varphi \theta\varphi} = \sin^2\theta$. By symmetry of the Riemann tensor, we see that $R_{\theta\varphi} = R_{\varphi\theta} = 0$. Thus, the Ricci tensor (written in matrix form) is
\begin{equation}
\text{Ricci} = \begin{pmatrix}  1 &amp;amp; 0 \\\  0 &amp;amp; \sin^2\theta \end{pmatrix}.
\end{equation}
The scalar curvature is now easy to compute:
\begin{equation}
R = g^{\theta\theta}R_{\theta\theta} + g^{\varphi\varphi} R_{\varphi\varphi} = 1 + \frac{1}{\sin^2\theta}\sin^2\theta = 2,
\end{equation} so that the sphere is of constant positive curvature, as expected. In fact, the scalar curvature computed in this fashion for surfaces is always twice the Gaussian curvature.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exerise.&lt;/strong&gt;
Compute the Ricci and scalar curvatures of $S^2$ using stereographic coordinates. &lt;em&gt;Solution:&lt;/em&gt; The Ricci curvature is
\begin{equation}
\text{Ricci} = \begin{pmatrix}  4/\rho &amp;amp; 0 \\\  0 &amp;amp; 4/\rho \end{pmatrix},
\end{equation}
and the scalar curvature is $R = 2$, which is consistent with the result from the previous example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The Torus $\mathbb{T}^2$.&lt;/em&gt;
The Ricci and scalar curvatures of the torus can be found by directly applying the formalism to the Riemann tensor we derived on the torus. By symmetry of the Riemann tensor, we again see that the components $R_{\theta\varphi} = R_{\varphi \theta} = 0$. It remains to compute the diagonal entries. Using the expression for the Ricci curvature, we have that $R_{\theta \theta} = R^{\theta}_{\theta \theta\theta} + R^{\varphi}_{\theta \varphi\theta} = R^{\varphi}_{\theta \varphi \theta} = \frac{r\cos\theta}{R+r\cos\theta}.$ Similarly, we compute $R_{\varphi\varphi}$ to be $R_{\varphi\varphi} = R^{\theta}_{\varphi \theta\varphi} = \frac{\cos\theta\left(R+r\cos\theta\right)}{r}$. The Ricci tensor is therefore
\begin{equation}
\text{Ricci} = \begin{pmatrix}  \frac{r\cos\theta}{R+r\cos\theta} &amp;amp; 0 \\\  0 &amp;amp; \frac{\cos\theta\left(R+r\cos\theta\right)}{r} \end{pmatrix}.
\end{equation}
We can then compute the scalar curvature as
\begin{equation}
R = g^{\theta\theta}R_{\theta\theta} + g^{\varphi\varphi} R_{\varphi\varphi} = \frac{1}{r^2}\left( \frac{r\cos\theta}{R+r\cos\theta}\right) + \frac{1}{(R+r\cos\theta)^2} \left(\frac{\cos\theta\left(R+r\cos\theta\right)}{r} \right) = \frac{2\cos\theta}{r(R+r\cos\theta)}.
\end{equation}
As a consistency check, let us compute the integrated total curvature:
\begin{align}
\int R dA  = \iint\ R \sqrt{g} d\theta d\varphi = \iint \left(\frac{2\cos\theta}{r(R+r\cos\theta)}\right) r(R+r\cos\theta) d\theta d\varphi = \iint 2\cos \theta d\theta d\varphi = 0,
\end{align}
which is consistent with the Gauss-Bonnet theorem ($\int_{\mathbb{T}^2} R dA  = 4\pi \chi (\mathbb{T}^2) = 0$).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt;&lt;em&gt;The Upper Half Plane $\mathbb{H}$.&lt;/em&gt;
We now compute the derived curvature quantities for the upper half plane. By symmetry, the off-diagonal components of the Ricci tensor are zero. The $xx$ component of the Ricci tensor is: $R_{xx} = R^x_{xxx} + R^y_{xyx} =  -1/y^2$. Similarly, $R_{yy} = R^x_{yxy} + R^y_{yyy} = -1/y^2$. Thus, the Ricci tensor is
\begin{equation}
\text{Ricci} = \begin{pmatrix}  -1/y^2 &amp;amp; 0 \\\  0 &amp;amp; -1/y^2 \end{pmatrix}.
\end{equation}
We can then compute the scalar curvature to be
\begin{equation}
R = g^{xx} R_{xx} + g^{yy} R_{yy} = -1 -1 = -2,
\end{equation}
So that the upper half plane is of constant negative curvature, as expected.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise.&lt;/strong&gt;
Compute the Ricci and scalar curvatures of the disc with the hyperbolic metric. &lt;em&gt;Solution:&lt;/em&gt; Recall that $\sigma(x,y) = 1 - x^2 - y^2$. The Ricci tensor is:
\begin{equation}
\text{Ricci} = \begin{pmatrix}  -2/\sigma^2 &amp;amp; 0 \\\  0 &amp;amp; -2/\sigma^2 \end{pmatrix}.
\end{equation}
The scalar curvature is $R = -2$, which agrees with the constant negative-curvature solution of the previous example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; &lt;em&gt;The 3-sphere $S^3$.&lt;/em&gt;
Using the expression for the Riemann tensor of the $3$-sphere, and the same procedure as before,
we compute the Ricci tensor to be
\begin{equation} \label{3-sphere-Ricci}
\text{Ricci} = 2\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; \sin^2\psi &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; \sin^2\psi \sin^2 \theta \end{pmatrix}.
\end{equation}
Taking the trace of this against the metric tensor, we compute the scalar curvature to be
\begin{equation}
R = g^{\psi\psi} R_{\psi \psi} + g^{\theta\theta} R_{\theta \theta} + g^{\varphi \varphi} R_{\varphi\varphi}
= 2 + 2 + 2 = 6,
\end{equation}
so that the $3$-sphere is a 3-manifold of constant curvature.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt;&lt;em&gt;The left-invariant metric on $S^3 \cong SU(2)$ &amp;amp; Hopf coordinates.&lt;/em&gt;
Using the expression we derived for the Riemann tensor in Hopf coordinates, we compute the nontrivial components of the Ricci tensor to be
$R_{\eta \eta} = 2$, $R_{\xi_1 \xi_1} = 2\sin^2 \eta$, and $R_{\xi_2 \xi_2} = 2\cos^2 \eta$, so that
\begin{equation}
\text{Ricci} = 2\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0\\\ 0 &amp;amp; \sin^2\psi &amp;amp; 0\\\ 0 &amp;amp; 0 &amp;amp; \cos^2\eta \end{pmatrix}.
\end{equation}
Contracting with the metric tensor, we obtain an expression for the scalar curvature:
\begin{equation}
R = g^{\eta \eta} R_{\eta \eta} + g^{\xi_1 \xi_1} R_{\xi_1 \xi_1} + g^{\xi_2 \xi_2} R_{\xi_2 \xi_2} = 2+2+2 = 6,
\end{equation}
which coincides with our previous result for the scalar curvature of $S^3$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The trifecta of Hilbert spaces on the unit disc</title>
      <link>/talk/hilbert-spaces-on-the-disc/</link>
      <pubDate>Thu, 01 Apr 2021 11:16:32 -0400</pubDate>
      <guid>/talk/hilbert-spaces-on-the-disc/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/1TB9cLz5Ja0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Hilbert spaces are common. Connection among them is rare. With this spirit, we will see the connection
among the three classical Hilbert spaces on the unit disc U. These Hilbert spaces are Hardy ($H^2(U)$), Dirichlet
($D^2(U)$) and lastly Bergman ($A^2(U)$). The idea comes from the intuition of evolving the remarkable identity called
as Littlewood Paley Identity for Bergman and Dirichlet spaces. During the presentation, audience will get to know more
about this identity. And also, the importance of this identity in the sense that how it relates to the Nevanlinna
Counting function. Nevanlinna Counting function $N_\phi(w)$ measures the &amp;lsquo;affinity&amp;rsquo; that $\phi$ has for value $w$ where
$\phi$ is a holomorphic map on $U$. Besides this, we will also see more connection among Hardy, Dirichlet and Riemann Zeta functions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Essentials of Viscosity Solutions in $R^n$</title>
      <link>/talk/the-essentials-of-viscosity-solutions/</link>
      <pubDate>Tue, 23 Mar 2021 16:11:32 -0400</pubDate>
      <guid>/talk/the-essentials-of-viscosity-solutions/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/0FRNeTc6Xyc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/I_fsCAW3xrM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/v3F4kv8f9v8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In their 1992 paper, authors Michael Crandall, Hitoshi Ishii, and Pierre-Louis Lions describe a class of solutions to certain 2nd order PDEs in R^n which they call &amp;ldquo;viscosity solutions&amp;rdquo;. In brief, a viscosity solution to an appropriate PDE is a continuous function possessing pointwise estimates for derivatives; they also possess a comparison principle which enables one to prove uniqueness of solutions to Dirichlet and Cauchy-Dirichlet problems. In this talk we will introduce the correct family of PDE for viscosity solutions; define viscosity solutions and prove their basic properties; discuss various results comparing viscosity and other notions of solutions; and, time permitting, we will also introduce a semicontinuous Perron&amp;rsquo;s method for existence of viscosity solutions and discuss parabolic viscosity solutions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A short Introduction to the Theta Functions</title>
      <link>/talk/introduction-to-theta-function/</link>
      <pubDate>Tue, 23 Mar 2021 16:10:38 -0400</pubDate>
      <guid>/talk/introduction-to-theta-function/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/cV9YMgCozsw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The theory of theta function plays an important role in finding exact (quasi-) periodic solutions to the nonlinear PDEs. In this talk, we will introduce first the concepts of Riemanns theta function (with characteristics) and Jacobis theta function. Then some of the simplest properties of those theta functions will be presented. If time permits, we will discuss a little bit about algebraic-geometry methods of constructing exact solution to KP equation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Methods of nonlinear equations in the theory of algebraic geometry</title>
      <link>/talk/riemann-schottky-problem/</link>
      <pubDate>Mon, 15 Feb 2021 13:50:43 -0500</pubDate>
      <guid>/talk/riemann-schottky-problem/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/asVgNLcnAz0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Methods of nonlinear equations in the theory of algebraic geometry&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Nathan Hayford&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date/time&lt;/strong&gt;: Wednesday, February 17th, 3:00pm-4:00pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:
The Riemann-Schottky problem, in modern language, asks for a characterization of Jacobian varieties of among abelian varieties. From Riemanns point of view, the question was to address the discrepancy between the 3g-3-dimensional space of moduli for compact Riemann surfaces of genus g from the g(g+1)/2-dimensional space of Siegel matrices, in which the space of Riemann surfaces embeds, via the period matrix. The problem remained open for almost a millennium. The first hint of a solution to this problem was found (somewhat surprisingly) by I. Krichever (1977), when he showed (more or less) that the period matrix for a Riemann surface could be used to construct tau functions for the KP hierarchy. S. Novikov conjectured that the converse also held, thus answering the Riemann-Schottky problem a la methods of integrable systems. This turned out to indeed be the case, with a proof from T. Shiota (1986) shortly thereafter. In this talk, I will attempt to fill in some of the details of this story, and explain some of the consequences of this theorem, both in integrable systems and algebraic geometry.&lt;/p&gt;
&lt;p&gt;Link to the Zoom meeting:  &lt;a href=&#34;https://zoom.us/j/96802432385&#34;&gt;https://zoom.us/j/96802432385&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Part II link: &lt;a href=&#34;https://zoom.us/s/97923273524&#34;&gt;https://zoom.us/s/97923273524&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Weyl&#39;s law and  hearing the area of a drum</title>
      <link>/talk/weyl-law-hear-area-drum/</link>
      <pubDate>Wed, 03 Feb 2021 14:24:34 -0500</pubDate>
      <guid>/talk/weyl-law-hear-area-drum/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/HiCA0n6x3Jo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/-nm5mjcNYDA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Weyl&amp;rsquo;s law and hearing the area of a drum&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Louis Arenas&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date/Time&lt;/strong&gt;: Wednesday, February 3rd, 3:00pm-4:00pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:
H. Lorentz in 1910 gave a series of lectures titled &amp;ldquo;Old and new problems in physics&amp;rdquo;. In the last lecture he mentions that J. Jean is interested in studying the growth rate of overtones of an electromagnetic wave in a bounded domain. He conjectures that the growth rate is independent of the shape of the domain and depends only on the volume and dimension of the domain. Herman Weyl, who was in attendance, precisely describes how fast these overtones grow two years after this lecture series. Since Weyl&amp;rsquo;s law holds for vibrating membranes, we start by describing the overtones of a drumhead via Dirichlet eigenvalues, compute the eigenvalues explicitly for a string with fixed ends, and build towards a proof of Weyl&amp;rsquo;s law in 2D for simply connected domains.&lt;/p&gt;
&lt;p&gt;Link to the Zoom Meeting: &lt;a href=&#34;https://zoom.us/j/92117761401&#34;&gt;https://zoom.us/j/92117761401&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prodsimplicial and p-path complexes on directed graphs</title>
      <link>/talk/p-path-complexes-on-directed-graphs/</link>
      <pubDate>Mon, 18 Jan 2021 14:09:46 -0500</pubDate>
      <guid>/talk/p-path-complexes-on-directed-graphs/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/9rlzTWD8o3o&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;:  Prodsimplicial and p-path complexes on directed graphs&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;:  Lina Fajardo Gomez&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date/Time&lt;/strong&gt;: Wednesday, January 20th, 2020&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: At face value, a graph is a simplicial complex that only has faces of dimension 0 (vertices) and 1 (edges). However, given appropriate definitions, higher dimensional cells can emerge. We present two such definitions, prodsimplicial complexes and p-path complexes, and compare in examples the homology groups obtained for different graphs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zoom Link&lt;/strong&gt;: &lt;a href=&#34;https://zoom.us/j/96345929862&#34;&gt;https://zoom.us/j/96345929862&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Strong Asymptotics of Planar Orthogonal Polynomials: Gaussian Weight Perturbed by Point Charges</title>
      <link>/talk/asymptotic-op/</link>
      <pubDate>Mon, 09 Nov 2020 13:22:22 -0500</pubDate>
      <guid>/talk/asymptotic-op/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Strong Asymptotics of Planar Orthogonal Polynomials: Gaussian Weight Perturbed by Point Charges&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Meng Yang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;

&lt;a href=&#34;https://drive.google.com/file/d/14SWXLKDks7bhNrO4tt3XrOQig0-uBWfD/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computing Reflection Coefficient of Schrondinger Operator via WKB method</title>
      <link>/posts/wkb-reflection/</link>
      <pubDate>Sun, 08 Nov 2020 23:25:17 -0500</pubDate>
      <guid>/posts/wkb-reflection/</guid>
      <description>&lt;p&gt;See the PDF:
&lt;script type=&#34;text/javascript&#34; src=&#34;/js/pdf-js/build/pdf.js&#34;&gt;&lt;/script&gt;
&lt;style&gt;
#the-canvas {
  border: 1px solid black;
  direction: ltr;
  width: 100%;
  height: auto;
}
#paginator{
    text-align: center;
    margin-bottom: 10px;
}
&lt;/style&gt;

&lt;div id=&#34;paginator&#34;&gt;
    &lt;button id=&#34;prev&#34;&gt;Previous&lt;/button&gt;
    &lt;button id=&#34;next&#34;&gt;Next&lt;/button&gt;
    &amp;nbsp; &amp;nbsp;
    &lt;span&gt;Page: &lt;span id=&#34;page_num&#34;&gt;&lt;/span&gt; / &lt;span id=&#34;page_count&#34;&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/div&gt;
&lt;div id=&#34;embed-pdf-container&#34;&gt;
    &lt;canvas id=&#34;the-canvas&#34;&gt;&lt;/canvas&gt;
&lt;/div&gt;

&lt;script type=&#34;text/javascript&#34;&gt;
window.onload = function() {



var url = &#34;\/pdf\/wkb.pdf&#34;;


var pdfjsLib = window[&#39;pdfjs-dist/build/pdf&#39;];


pdfjsLib.GlobalWorkerOptions.workerSrc = &#39;/js/pdf-js/build/pdf.worker.js&#39;;


var pdfDoc = null,
    pageNum = 1,
    pageRendering = false,
    pageNumPending = null,
    scale = 3,
    canvas = document.getElementById(&#39;the-canvas&#39;),
    ctx = canvas.getContext(&#39;2d&#39;);



function renderPage(num) {
  pageRendering = true;
  
  pdfDoc.getPage(num).then(function(page) {
    var viewport = page.getViewport({scale: scale});
    canvas.height = viewport.height;
    canvas.width = viewport.width;

    
    var renderContext = {
      canvasContext: ctx,
      viewport: viewport
    };
    var renderTask = page.render(renderContext);

    
    renderTask.promise.then(function() {
      pageRendering = false;
      if (pageNumPending !== null) {
        
        renderPage(pageNumPending);
        pageNumPending = null;
      }
    });
  });

  
  document.getElementById(&#39;page_num&#39;).textContent = num;
}



function queueRenderPage(num) {
  if (pageRendering) {
    pageNumPending = num;
  } else {
    renderPage(num);
  }
}



function onPrevPage() {
  if (pageNum &lt;= 1) {
    return;
  }
  pageNum--;
  queueRenderPage(pageNum);
}
document.getElementById(&#39;prev&#39;).addEventListener(&#39;click&#39;, onPrevPage);



function onNextPage() {
  if (pageNum &gt;= pdfDoc.numPages) {
    return;
  }
  pageNum++;
  queueRenderPage(pageNum);
}
document.getElementById(&#39;next&#39;).addEventListener(&#39;click&#39;, onNextPage);



pdfjsLib.getDocument(url).promise.then(function(pdfDoc_) {
  pdfDoc = pdfDoc_;
  document.getElementById(&#39;page_count&#39;).textContent = pdfDoc.numPages;

  
  renderPage(pageNum);
});
}

&lt;/script&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fractional Calculus Approach for Flow Model in Porous Media</title>
      <link>/talk/fractional-calculus-approach/</link>
      <pubDate>Sun, 08 Nov 2020 23:12:31 -0500</pubDate>
      <guid>/talk/fractional-calculus-approach/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Jb1eEDQBUPw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Fractional Calculus Approach for Flow Model in Porous Media&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;
The Fractional Calculus approach is introduced into reservoir simulation. A three-dimensional relaxation model for viscoelastic fluid is built. The model based on the exact solution in Laplace space for some unsteady flow-Maxwell flow in an infinite reservoir  is obtained by Laplace transform and Fourier transform.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On solving the Dirichlet problem</title>
      <link>/talk/dirchlet-problem/</link>
      <pubDate>Mon, 02 Nov 2020 23:12:31 -0500</pubDate>
      <guid>/talk/dirchlet-problem/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Vu6MB6TQuns&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;strong&gt;Title&lt;/strong&gt;: On solving the Dirichlet problem&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Louis Arenas&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: October 23rd&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 11:00 pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: The talk will start by reviewing the mainstream strategies for solving the problem on simply connected domains, with particular attention to the disk. It is hoped that we have enough time to talk about Malmheden&amp;rsquo;s strategy for solving the problem on the disk. The talk should be of interest to anyone taking or wanting a review of basic concepts in complex analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Survey of Equilibrium in the Plane</title>
      <link>/talk/a-survey-of-equilibruim-in-the-plane/</link>
      <pubDate>Wed, 02 Sep 2020 15:01:51 -0400</pubDate>
      <guid>/talk/a-survey-of-equilibruim-in-the-plane/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Hye1gkDkCxU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: A survey of equilibrium in the plane&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Nathan Hayford&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Friday, September 4th&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 11:00am&lt;/p&gt;
&lt;p&gt;Abstract: Finding equilibria of charge distributions in the plane is a classical problem, which has found numerous applications in many other areas of mathematics and physics, including approximation theory, random matrices, quantum gravity, and integrable systems, among others. In this talk, I will survey some classical results from the theory of equilibrium distributions (using the language of potential theory), and provide some physical intuition for why such formulas hold. We will consider equilibrium with and without external fields. Furthermore, I will discuss some of the more modern applications of the subject; in particular, I will sketch how the equilibrium measures help us describe the asymptotics of certain families of orthogonal polynomials, as well how such problems appear in integrable systems, if time permits.&lt;/p&gt;
&lt;p&gt;Link to zoom meeting: &lt;a href=&#34;https://zoom.us/j/93365223865&#34;&gt;https://zoom.us/j/93365223865&lt;/a&gt;
&lt;strong&gt;Video&lt;/strong&gt;: 
&lt;a href=&#34;https://www.youtube.com/watch?v=Hye1gkDkCxU&amp;amp;t=2780s&amp;amp;ab_channel=USFGradMath&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Asymptotic Methods in Analysis</title>
      <link>/talk/asymptotic-methods-in-analysis/</link>
      <pubDate>Sat, 22 Aug 2020 14:47:05 -0400</pubDate>
      <guid>/talk/asymptotic-methods-in-analysis/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/nDw2wLPQv3M&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Asymptotic Methods in Analysis&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Fudong Wang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, 27th August.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00 pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: In this talk, I will introduce the history of several well-known asymptotic methods in analysis. Then we will apply those methods via examples. The first example would be to apply Laplace&amp;rsquo;s method to get one of the oldest asymptotic results, the Stirling&amp;rsquo;s formula, i.e.
$$n!\sim e^{-n}n^n\sqrt{2\pi n},n\rightarrow \infty.$$ Next example is to apply the saddle point method to get the asymptotic of the integral
$$\int_{\mathbb{R}}f(z)e^{it(z^2+z)}dz,\quad t\rightarrow \infty .$$ Then I will introduce one recently developed asymptotic method called $\bar{\partial}-$steepest descent method, and apply it to study the long-time asymptotic for the linear Schrdinger equation:
$$
iu_t+u_{xx}=0,\quad
u(x,0)=q(x)\in H^1(\mathbb{R}).
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;zoom&lt;/strong&gt;:
&lt;a href=&#34;https://zoom.us/j/98760291675&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Primes of the Form $p = x^2 &#43; ny^2$</title>
      <link>/talk/primes-of-the-form/</link>
      <pubDate>Mon, 03 Aug 2020 10:44:14 -0400</pubDate>
      <guid>/talk/primes-of-the-form/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/VBPrP4nChbo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;strong&gt;Title&lt;/strong&gt;: Primes of the form $p = x^2 + ny^2$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Louis Arenas&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, August 6th&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: In a letter to Mersenne, dated 1640, Fermat formulated a problem asking for sufficient conditions to the titular primes in the case when $n=1,2,3.$ The first well known proof to the original problem (in the case for when $n=1$) was published by Euler in 1749, with the other two cases being completed in 1772. Naturally, Euler attempted to generalize the problem for arbitrary integers n &amp;gt; 0; while not producing any proofs, the ideas that Euler touched on would be expanded by Legendre, Gauss, and Lagrange. The goal for this talk is to outline a strategy that answers Fermat&amp;rsquo;s original problem along with a few more cases. If time permits, we&amp;rsquo;ll just mention a result that solves the general problem for countably many n integers.&lt;/p&gt;
&lt;p&gt;Link to Zoom meeting: &lt;a href=&#34;https://zoom.us/j/98801740991&#34;&gt;https://zoom.us/j/98801740991&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Video: 
&lt;a href=&#34;https://drive.google.com/file/d/1iVpAtU8iRoVYILWLTB6MgfUe9ugrYsme/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Matroids</title>
      <link>/talk/introduction-to-matroids/</link>
      <pubDate>Mon, 27 Jul 2020 22:36:21 -0400</pubDate>
      <guid>/talk/introduction-to-matroids/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/SljIEkfzloA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;strong&gt;Title&lt;/strong&gt;: Introduction to matroids&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Lina Fajardo Gomez&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, July 30th&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: Matroids are mathematical objects that abstract the notion of linearly independent sets. They have applications in many areas of mathematics, ranging from combinatorics to field theory. In this talk I will give an overview of matroids, why they are studied and why I in particular took an interest in them.&lt;/p&gt;
&lt;p&gt;Link to Zoom meeting: &lt;a href=&#34;https://zoom.us/j/93617336971&#34;&gt;https://zoom.us/j/93617336971&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;: 
&lt;a href=&#34;https://drive.google.com/file/d/1V3Zg0KFIyk32S_mg2mMJ9I4lpIBchM70/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: 
&lt;a href=&#34;https://drive.google.com/file/d/1tP9Qh3RJCplCVUsds1U9EBmmZd7hEZr0/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Doing research as a student: tips and tricks</title>
      <link>/talk/doing-research-as-a-student/</link>
      <pubDate>Mon, 20 Jul 2020 11:41:42 -0400</pubDate>
      <guid>/talk/doing-research-as-a-student/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Doing research as a student: tips and tricks&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Giacomo Micheli&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, July 23rd&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00pm&lt;/p&gt;
&lt;p&gt;Abstract:
In this talk I will first explain how the publication process works. Then, I will go through some advice to do research as a student. In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;some of the methods I found most effective when I was doing independent research as a student.&lt;/li&gt;
&lt;li&gt;some general advice related to the process of submitting a paper to a journal.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Link to Zoom meeting: &lt;a href=&#34;https://zoom.us/j/95032330155&#34;&gt;https://zoom.us/j/95032330155&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Gentle Introduction to Infinite-Dimensional Lie Algebras</title>
      <link>/talk/usf/infinite-lie-algebra/</link>
      <pubDate>Sun, 05 Jul 2020 17:55:36 -0400</pubDate>
      <guid>/talk/usf/infinite-lie-algebra/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/6789LcHqwP4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: A Gentle Introduction to Infinite-Dimensional Lie Algebras&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Nathan Hayford&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, July 9th&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00 pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: Infinite-dimensional Lie algebras have found applications in conformal field theory, integrable systems, and number theory, among other areas of mathematics. However, one wonders exactly how these algebras arise in such contexts, and moreover what is even meant by infinite-dimensional Lie algebra in the first place. In this talk, I will try to give a friendly introduction to the field of infinite-dimensional Lie algebras, and try to give the listener some operational familiarity with these structures by providing a few explicit examples. Furthermore, I will mention a few specific problems in mathematics where such algebras have been useful.&lt;/p&gt;
&lt;p&gt;Link to Zoom meeting: &lt;a href=&#34;https://zoom.us/j/5082038044?pwd=YUVBdkZvZU5RYXBYZmU5ZGRFZnE1Zz09&#34;&gt;https://zoom.us/j/5082038044?pwd=YUVBdkZvZU5RYXBYZmU5ZGRFZnE1Zz09&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video:&lt;/strong&gt;
&lt;a href=&#34;https://drive.google.com/file/d/1by6zBTatZNO3CxFXer75CTtHR3hujoP5/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides:&lt;/strong&gt; 
&lt;a href=&#34;https://drive.google.com/file/d/1zPw8vC7dRtkJMMvsjc5SuMQeIlKBsUxV/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Nevanlinna-Pick Interpolation Problem</title>
      <link>/talk/nevanlinna-pick-problem/</link>
      <pubDate>Mon, 29 Jun 2020 13:37:03 -0400</pubDate>
      <guid>/talk/nevanlinna-pick-problem/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/C8-0k_UJnj8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;strong&gt;Title&lt;/strong&gt;: The Nevanlinna-Pick Interpolation Problem&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: John Kyei&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, July 2nd&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:
In this presentation, I will give an introductory discussion on the general Nevanlina-Pick Interpolation problem . Formulation of the Pick Problem and the nature of solutions to the Extremal Pick Problem. Subsequently, Nevalinna Formulation.
We will  also look at  the Finite Blaschke Products, Basic  analytic  and algebraic properties such as the characterizations of holomorphic functions on the disk, approximation and Differentiation of the Finite Blaschke Product.&lt;/p&gt;
&lt;p&gt;Link to Zoom Meeting: &lt;a href=&#34;https://zoom.us/j/99109270972&#34;&gt;https://zoom.us/j/99109270972&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;: 
&lt;a href=&#34;https://drive.google.com/file/d/1_eVKFcjc5syRvp8s0CMusthbjAcX9EmX/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;:
&lt;a href=&#34;https://drive.google.com/file/d/1wXFhZwWLGglGkBkSF67V9GKNmdav8GKb/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stochastic Games for PDE</title>
      <link>/talk/usf/stochastic-games/</link>
      <pubDate>Sat, 20 Jun 2020 22:58:12 -0400</pubDate>
      <guid>/talk/usf/stochastic-games/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/TWf_XLzzUPI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Stochastic Games for PDE&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: 2:00 pm, Thursday, June 25th, 2020&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Forrest, Zachary&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: This talk will serve as an introduction to techniques of stochastic games and their application to proving the existence of viscosity solutions to second order, degenerate-elliptic equations. We will define such equations and the class of viscosity solutions; give definitions and properties of martingales and stopping times, including Doob&amp;rsquo;s Optimal Sampling theorem; and give examples of stochastic games for Pucci&amp;rsquo;s maximal operators and the p-Laplace equation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;:
&lt;a href=&#34;https://drive.google.com/file/d/1QlZqbhVYxEg6V5DHfCKCYfzpxzelyGXH/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;:
&lt;a href=&#34;https://drive.google.com/file/d/1zSpf3r2OzizRkmCB7auiWQ5-fH9F1-81/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Brief Introduction to Differential Geometry and Minimal Surfaces</title>
      <link>/talk/minimal-surfaces/</link>
      <pubDate>Sat, 13 Jun 2020 14:54:17 -0400</pubDate>
      <guid>/talk/minimal-surfaces/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/-FYXPfWy-bg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;strong&gt;Title&lt;/strong&gt;: A Brief Introduction to Differential Geometry and Minimal Surfaces&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, June 18&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00 pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Hayden Hunter (University of Florida)&lt;/p&gt;
&lt;p&gt;Abstract: For this lecture we will be providing a small introduction to Differential Geometry including the definition of a regular surface, first and second Fundamental Forms, and Gauss and Mean Curvature. From here we shall move to describing what a minimal surface is as well as proving their existence and certain properties of minimal surfaces.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;:
&lt;a href=&#34;https://drive.google.com/file/d/1h140EIRR51Ny9tkXAHYJQFapxTHXuPRb/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Drive&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Elementary Introdcution to Fredholm Determinants</title>
      <link>/talk/fredholm-determinants/</link>
      <pubDate>Mon, 08 Jun 2020 13:01:12 -0400</pubDate>
      <guid>/talk/fredholm-determinants/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/m1CAUg0im4M&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: An Elementary Introduction to Fredholm Determinants&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speaker&lt;/strong&gt;: Fudong Wang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date&lt;/strong&gt;: Thursday, June 11&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: 2:00 pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: At the beginning of the 20th century, Fredholm introduced a way to solve a class of linear integral equations which are now called them Fredholm integral equations. In his 1903&amp;rsquo;s paper, Fredholm introduced a determinant of a functional, which now is called Fredholm determinant. In this lecture, we will begin with the definition of determinant in the finite-dimensional spaces and review some properties of the determinants. After that, we will focus on the determinant of form $det(I+F)$ where $F$ is &amp;ldquo;small&amp;rdquo;. Following 
&lt;a href=&#34;https://drive.google.com/file/d/1ebU0SUTSXsVQclHXe9sNFJg3YZmiGmtF/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fredholm&amp;rsquo;s 1903 paper&lt;/a&gt;, we will discuss Fredholm determinant $D_f$ and explore some properties of the determinant and how it connects to the finite determinants. Lastly, we will discuss how to construct the famous &amp;ldquo;soliton&amp;rdquo; solution to the equation of Koreteweg-de Vries by the so-called Fredholm determinant method introduced by Pppe(1983).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;: 
&lt;a href=&#34;https://drive.google.com/file/d/1ghnW1hZSzLleX_UQ-t9g7BcbN1-RonFt/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;google drive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Quantum invariants of framed links from cohomology of self-distributive structures</title>
      <link>/talk/usf/quantum-invariants/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/talk/usf/quantum-invariants/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Emanuele Zappala&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time:&lt;/strong&gt; 2:00pm, Thursday, June 4&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In this talk I will give a brief introduction to knot theory and the notion of knot invariant. Next I will describe the process of algebraization of knot theory which naturally gives Yang-Baxter operators, Yetter-Drinfeld modules and racks/quandles etc. After recalling the definition of cohomology of racks, I will proceed to show how to construct an invariant of links and knotted surfaces from cocycles. I will therefore explain some recent joint works with M. Elhamdadi and M. Saito relating self-distributivity of higher arity structures and invariants of framed links, with a (categorical) perspective on how to realize them as quantum invariants.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zoom links&lt;/strong&gt;: 
&lt;a href=&#34;https://zoom.us/j/99982471312?pwd=Z0NTR2UraHZTQXI5TkdzNlM5K0FPUT09&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;click me.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: 
&lt;a href=&#34;https://drive.google.com/file/d/1Pef6VJyfGRqouX5uf-QIy3oITf0NW85P/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;google drive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Darboux Transformation and Soliton Equations </title>
      <link>/talk/usf/darboux-transformation-and-soliton-equations/</link>
      <pubDate>Thu, 20 Feb 2020 20:47:23 -0400</pubDate>
      <guid>/talk/usf/darboux-transformation-and-soliton-equations/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Darboux transformation and soliton equations.&lt;br&gt;
&lt;strong&gt;Speaker:&lt;/strong&gt; Yehui Huang (North China Electric Power University).&lt;br&gt;
&lt;strong&gt;Date:&lt;/strong&gt; Thursday, February $20^{th}$&lt;br&gt;
&lt;strong&gt;Time:&lt;/strong&gt; 11:00am&lt;br&gt;
&lt;strong&gt;Place:&lt;/strong&gt; CIS 1045&lt;br&gt;
&lt;strong&gt;Abstract:&lt;/strong&gt; In this talk, I will introduce a transformation originated
by Darboux in his study of the linear Sturm-Liouville problem. By
generalized Darboux transformations, I will present a solution formula
with multiple parameters for some soliton equations, including KdV and
NLS. After taking special choices for the seed solution and the
eigenfunctions, different types of exact solutions are derived, which
include solitons, breathers and rogue wave solutions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Caldern Problem</title>
      <link>/talk/usf/the-calderon-problem/</link>
      <pubDate>Sat, 15 Feb 2020 20:55:08 -0400</pubDate>
      <guid>/talk/usf/the-calderon-problem/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; The Caldern problem.&lt;br&gt;
&lt;strong&gt;Speaker:&lt;/strong&gt; Lina Fajardo Gomez.&lt;br&gt;
&lt;strong&gt;Date:&lt;/strong&gt; Thursday, February $13^{th}$&lt;br&gt;
&lt;strong&gt;Time:&lt;/strong&gt; 11:00am&lt;br&gt;
&lt;strong&gt;Place:&lt;/strong&gt; CIS 1023&lt;br&gt;
&lt;strong&gt;Abstract:&lt;/strong&gt; What do oil drilling and tumor detection have in common?
How could nonlinear equations be easier to work with? The Caldern
problem was first introduced as an inverse boundary value problem: how
information about the boundary of a domain can be used to determine
information about its interior. We will discuss the set up, some
applications, and a proposed solution for a class of Caldern type
inverse problems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variation Problem and How to Solve It</title>
      <link>/talk/usf/variation-problem-and-how-to-solve-it/</link>
      <pubDate>Sat, 01 Feb 2020 21:02:58 -0400</pubDate>
      <guid>/talk/usf/variation-problem-and-how-to-solve-it/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Variational Problems and How to Solve Them.&lt;br&gt;
&lt;strong&gt;Speaker:&lt;/strong&gt; Nathan Hayford.&lt;br&gt;
&lt;strong&gt;Date:&lt;/strong&gt; Thursday, February $6^{th}$&lt;br&gt;
&lt;strong&gt;Time:&lt;/strong&gt; 11:00am&lt;br&gt;
&lt;strong&gt;Place:&lt;/strong&gt; CIS 1023&lt;br&gt;
&lt;strong&gt;Abstract:&lt;/strong&gt; Many problems in math and physics arise as problems of
extremizing some functional. Such problems include the isoperimetric
problem, minimal surface problem, and the formulation of Lagrangian
mechanics. We shall discuss the calculus of variations, and provide
worked out examples of how these techniques may be applied to solve such
problems. We will also discuss how such techniques may be applied to
write Lagrangian formulations of theories like electromagnetism and
general relativity, if time permits.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lorentz Group</title>
      <link>/talk/usf/lorentz-group/</link>
      <pubDate>Thu, 30 Jan 2020 21:05:22 -0400</pubDate>
      <guid>/talk/usf/lorentz-group/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Introduction to the Lorentz Group.&lt;br&gt;
&lt;strong&gt;Speaker:&lt;/strong&gt; Louis Arenas.&lt;br&gt;
&lt;strong&gt;Date:&lt;/strong&gt; Thursday, January $30^{th}$&lt;br&gt;
&lt;strong&gt;Time:&lt;/strong&gt; 11:00am&lt;br&gt;
&lt;strong&gt;Place:&lt;/strong&gt; CIS 1023&lt;br&gt;
&lt;strong&gt;Abstract:&lt;/strong&gt; The goal of this talk is to introduce the audience to the
definition of the Lorentz group and motivation in general relativity. We
will derive commutation relations, and if time permits show the
restricted Lorentz group is isomorphic to the Mbius group.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Riemann Hilbert Problem</title>
      <link>/talk/usf/riemann-hilbert-problem/</link>
      <pubDate>Thu, 23 Jan 2020 21:05:34 -0400</pubDate>
      <guid>/talk/usf/riemann-hilbert-problem/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Introduction to the Riemann-Hilbert Problem in $L^p$-space.&lt;br&gt;
&lt;strong&gt;Speaker:&lt;/strong&gt; Fudong Wang.&lt;br&gt;
&lt;strong&gt;Date:&lt;/strong&gt; Thursday, January $23^{rd}$&lt;br&gt;
&lt;strong&gt;Time:&lt;/strong&gt; 11:00am&lt;br&gt;
&lt;strong&gt;Place:&lt;/strong&gt; CIS 1023&lt;br&gt;
&lt;strong&gt;Abstract:&lt;/strong&gt; We will first introduce some fundamental results about the
Cauchy operator. Base on the Cauchy operator, we will make it precise
what is the RHP and what is the solution to an RHP. Then we will talk
about the two types of inhomogeneous Riemann-Hilbert problems and
establish the equivalence between them. Finally, a uniqueness theorem of
RHP in $L^p$ will be given. If time permits, its application to the
inverse scattering theory will be mentioned too.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
